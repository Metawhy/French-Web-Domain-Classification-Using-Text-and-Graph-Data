   #next

   Navigate

     * Home
     * Data Infrastructure
     * Technology Trends
     * Company
     * Subscribe to Our Newsletter

     *
     *
     *
     *

   (BUTTON)

   (BUTTON)

Western Digital Corporate Blog

   (BUTTON)
   September 20, 2019

The Demise of the Centralized Data Center

   September 19, 2019

The Industry 4.0 Transition – Architecting for AI, ML and IoT

   September 17, 2019

Virtualization and Your Data Strategy – Top Resources

   September 16, 2019

Examples of Unstructured Data ⁠— 4 Enterprise Use Cases

     * Applications

The Demise of the Centralized Data Center

   The centralized data center model is increasingly outmoded as new types
   of data, such as… Read More
   September 20, 2019
     * IIoT
     * Technology Trends

The Industry 4.0 Transition – Architecting for AI, ML and IoT

   To fully utilize the benefits of AI and ML computing to accelerate the
   journey towards… Read More
   September 19, 2019
     * Applications

Virtualization and Your Data Strategy – Top Resources

   Following VMworld 2019, we’ve re-capped a few of the hot items that you
   might want… Read More
   September 17, 2019
     * Applications

Examples of Unstructured Data ⁠— 4 Enterprise Use Cases

   Examples of unstructured data include large media files, massive
   databases, data lakes, and architectural information… Read More
   September 16, 2019
     * Tech & Products

How to Maximize Storage Efficiency? Say Goodbye to Human Intervention

   Traditional high touch monitoring tools cannot adapt to the dynamic
   environments of today nor scale… Read More
   September 13, 2019
     * Industries

The Latest from WD_BLACK: Performance Drives, Purpose-Built for Gaming

   Gamers often feel the pain of deciding which old games to delete in
   order to… Read More
   September 11, 2019
     * Applications

How to Shift to a Modern Data Protection Architecture

   Modern data protection is seeing fast-paced changes often requiring a
   new approach. Here are four… Read More
   September 10, 2019
     * Tech & Products

Why NTB-Based NVDIMM Mirroring is a Better Choice

   Performance is architected from the inside. Here's why we chose NVDIMM
   NTB-based mirroring for high… Read More
   September 9, 2019
     * Tech & Products

JBOD vs. RAID vs. Erasure Coding

   We explain the difference between these configurations, and the value
   that JBOD and RAID stand… Read More
   September 4, 2019
     * AI and ML

6 Ways to Optimize the Cost of Your Big Data Platform

   Here are our tips and tricks about how to evaluate and optimize costs
   for a… Read More
   September 3, 2019
   Next»

   This blog includes news across the Western Digital® portfolio
   including: G-Technology, SanDisk, Upthere, WD and Western Digital.

   Western Digital Technologies, Inc. is the seller of record and licensee
   in the Americas of SanDisk® products.

   CAUTIONARY STATEMENT REGARDING FORWARD-LOOKING STATEMENTS: This website
   may contain forward-looking statements, including statements relating
   to expectations for our product portfolio, the market for our products,
   product development efforts, and the capacities, capabilities and
   applications of our products. These forward-looking statements are
   subject to risks and uncertainties that could cause actual results to
   differ materially from those expressed in the forward-looking
   statements, including development challenges or delays, supply chain
   and logistics issues, changes in markets, demand, global economic
   conditions and other risks and uncertainties listed in Western Digital
   Corporation’s most recent quarterly and annual reports filed with the
   Securities and Exchange Commission, to which your attention is
   directed. Readers are cautioned not to place undue reliance on these
   forward-looking statements and we undertake no obligation to update
   these forward-looking statements to reflect subsequent events or
   circumstances.

     * PRIVACY POLICY
     * YOUR CALIFORNIA PRIVACY RIGHTS
     * TERMS AND CONDITIONS

     *
     *
     *
     *

   © 2019 Western Digital Corporation or its affiliates. All rights
   reserved. | View Non-AMP Version
   X

Your choice regarding cookies

   We use cookies to enhance the performance of our site and give you a
   great user experience.
   For More information about Privacy Click Here
   (BUTTON) Accept
   (BUTTON) Reject
   Privacy Settings

   Powered by AMPforWP

   Type your search query and hit enter: 1___________________
   ____________________ Search

   (BUTTON) X
   #next Western Digital Corporate Blog » Feed Western Digital Corporate
   Blog » Comments Feed Western Digital Corporate Blog » Posts by
   Editorial Team Feed

   IFRAME: https://www.googletagmanager.com/ns.html?id=GTM-MB43D4S

   (BUTTON)
     * Data Infrastructure
     * Technology Trends
     * Company

     * Data Infrastructure
     * Technology Trends
     * Company

     * Search for: ____________________ (BUTTON) Search
       (BUTTON)
     *

Get our latest news and stories delivered to your inbox
       ____________________ ____________________ Get Updates
       Please provide a valid email address.
       By providing your email address, you agree to the terms of Western
       Digital’s Privacy Statement
       Please wait. Submission in progress...

Thank you! Your confirmation email will arrive shortly.
       Please be sure to check your spam folder and confirm your email
       address to ensure you receive your updates.

   Archive banner
   Editorial Team
   Editorial Team
   All things data with news and insights on systems and technology that
   help you capture, preserve, access and transform your data. We create
   environments for your data to thrive.
   All things data with news and insights on systems and technology that
   help you capture, preserve, access and transform your data.

   Filter by
   Filter By

Category

Tag

   data quality

3 Things We Learned (the Hard Way) About Data Quality

   ActiveScale|Analytics|Machine Learning|Smart Factory
   Western Digital built a top-tier big data platform for our
   manufacturing business. Here are 3 key lessons we learned about data
   quality for analytics…
   October 4, 2019
   See more posts by Editorial Team By Editorial Team

   A room full of attentive attendees at a conference.

4 Reasons You Should Be Excited at OCP Amsterdam

   Data Center|Open Source|ZNS|Zoned Storage
   The open-source community is pushing forward new technology to make
   hardware more flexible, scalable, and efficient. As a leader in ...
   September 25, 2019
   See more posts by Editorial Team By Editorial Team

   virtualization and data strategy

Virtualization and Your Data Strategy – Top Resources

   Data Center|Data Strategy|Virtualization
   Following VMworld 2019, we’ve re-capped a few of the hot items that you
   might want to check out to understand or adopt Data @ the Center and…
   September 17, 2019
   See more posts by Editorial Team By Editorial Team

   big data platform

6 Ways to Optimize the Cost of Your Big Data Platform

   Analytics|Big Data|CIO
   Here are our tips and tricks about how to evaluate and optimize costs
   for a big data platform.
   September 3, 2019
   See more posts by Editorial Team By Editorial Team

   Mark Peters

Data Strategy: Conversations with Mark Peters, Principal Analyst, ESG Global

   CIO|Data Center|Data Strategy
   We sat down with Mark Peters from ESG Global to get his insights about
   building a data strategy and how to effectively execute on it.
   August 28, 2019
   See more posts by Editorial Team By Editorial Team

   NVMe Guide to Virtualization

NVMe™ Guide to Virtualization

   NVMe|Virtualization
   Here's why the NVMe protocol, coupled with virtualization, will be
   pervasive as organizations continue to unlock the power of their
   ever-growing data.
   August 6, 2019
   See more posts by Editorial Team By Editorial Team

Building a Data Analytics Platform? Start by Futureproofing

   Analytics|Big Data|Data Strategy
   Are you building a data analytics platform? Here's why futureproofing
   is a key concept you should adopt when approaching data analytics
   platform…
   July 22, 2019
   See more posts by Editorial Team By Editorial Team

   NVMe-oF NVME Over Fabrics

NVMe-oF™: Answers to Your Most Asked Questions

   NVMe|NVMe-oF|OpenFlex
   Key answers to your questions about NVMe-oF protocol and the fabric
   that stitches it together.
   June 28, 2019
   See more posts by Editorial Team By Editorial Team

   NVMe adoption

NVMe™: A Guide To Adoption

   Data Center|NVMe|NVMe-oF
   As you proceed in building a data strategy, here's how to evaluate
   tapping into the benefits of NVMe and understanding the best practices
   for NVMe…
   May 30, 2019
   See more posts by Editorial Team By Editorial Team

   Here's What Keeps Western Digital's Women Leaders Going

Here’s What Keeps Western Digital’s Women Leaders Going

   Careers|Diversity
   What makes a leader great? To find out, we sat down with some of our
   top leaders, who have a combined 113 years of experience at Western
   Digital.
   March 8, 2019
   See more posts by Editorial Team By Editorial Team

   Next Page »

     *
     *
     *
     *

   Western Digital creates environments for data to thrive. We are driving
   the innovation needed to help customers capture, preserve, access and
   transform an ever-increasing diversity of data. Everywhere data lives,
   from advanced data centers to mobile sensors to personal devices, our
   industry-leading solutions deliver the possibilities of data. This blog
   includes news across the Western Digital® portfolio including:

     *
     *
     *
     *
     *

   Western Digital Technologies, Inc. is the seller of record and licensee
   in the Americas of SanDisk® products. CAUTIONARY STATEMENT REGARDING
   FORWARD-LOOKING STATEMENTS: This website may contain forward-looking
   statements, including statements relating to expectations for our
   product portfolio, the market for our products, product development
   efforts, and the capacities, capabilities and applications of our
   products. These forward-looking statements are subject to risks and
   uncertainties that could cause actual results to differ materially from
   those expressed in the forward-looking statements, including
   development challenges or delays, supply chain and logistics issues,
   changes in markets, demand, global economic conditions and other risks
   and uncertainties listed in Western Digital Corporation’s most recent
   quarterly and annual reports filed with the Securities and Exchange
   Commission, to which your attention is directed. Readers are cautioned
   not to place undue reliance on these forward-looking statements and we
   undertake no obligation to update these forward-looking statements to
   reflect subsequent events or circumstances.

   © 2019 Western Digital Corporation or its affiliates. All rights
   reserved.

     * Privacy Policy
     * Your California Privacy Rights
     * Terms and Conditions
   Navigate
     * Home
     * Data Infrastructure
     * Technology Trends
     * Company
     * Subscribe to Our Newsletter

     *
     *
     *
     *

   (BUTTON)

   (BUTTON)
   (BUTTON)

3 Things We Learned (the Hard Way) About Data Quality

     * Editorial Team in AI and ML

   The definition of data quality is not straightforward. It is rather a
   qualitative assessment of how well data can serve its purpose in a
   specific context. There are many definitions of what data quality is,
   or can be, and it is usually based on a multitude of factors critical
   for the contextual purpose.

   Over the last six years we’ve built a top-tier big data platform for
   our manufacturing business. Here are the three key lessons we learned
   about data quality for analytics and its impact on business:

Video Transcript

   Hi, my name is JuneAn Lanigan and I am the global leader of enterprise
   data management at Western Digital. Over the last six years, we have
   been building out a scalable big data platform and ecosystem, and I’m
   really excited to share with you some of the things that we have done
   to build a best-in-class platform, but also some of the learnings that
   we’ve had.

Impact of Data Quality on Business Needs

   In thinking about building out a platform that truly scales, you have
   to think about what are the needs of the business today, what are the
   current technologies, but you have to start looking at what is the
   future – what is the future of the business need as they evolve in
   their analytics capabilities? And [you need to] really place some bets
   on technology. But, one of the fundamental things that we’ve learned is
   around the importance of data quality.

   I run enterprise data management. I certainly understand quality, but
   “quality” has many, many dimensions to it, and so we really have to
   look at how are we performing on multiple dimensions – the completeness
   of the data, the accuracy of the data, the latency of the data, and
   certainly the cost of the data. So, I’d like to share some of the
   things that we’ve learned [about data quality].

Data Completeness

   One of the critical factors to consider is data completeness, and I
   think it makes sense that as you move data, in our case from different
   factories across the network to a cloud environment, that you have to
   make sure that whatever the data is you picked up is the data you
   actually inserted into the tables in the cloud. That’s an expectation
   and it’s a reasonable expectation because we’re supporting analytics in
   this big data environment and those analytics have far-reaching value
   to the business, to the bottom line.

     If we have the opportunity to take out millions of dollars of costs
     based on our analysis, we have to make sure that the data is
     accurate

   So, if we have the opportunity to take out millions of dollars of costs
   based on our analysis, we have to make sure that the data is accurate
   from which they’re making those decisions. What we found though is that
   we weren’t meeting the quality standards that we needed to, and we
   benchmarked our own data and tried to set a threshold of 85 percent,
   but even that isn’t good enough for the business when they’re banking
   on that data to make their decisions.

   And, so what we did was we implemented our Western Digital ActiveScale™
   in our Las Vegas data centers so that we could actually bring our data
   directly from the factory to our on-premises location before we brought
   that data to the cloud. What we were able to accomplish is a consistent
   five 9’s data quality across all of our various pipelines. It used to
   be that I’d have to report to the business daily as to how we were
   doing against our benchmarks. I still look at those metrics, but they
   don’t anymore. They can trust the data.

Data Accuracy

   The next point to consider is data accuracy, and this is where I like
   to say beauty is in the eye of the beholder because everybody uses the
   data differently. So, if you are a product program manager, you’ll
   define the data based on your perspective and what you’re trying to
   accomplish with those parameters, but a test engineer or manufacturing
   operations may be using that data differently. And, therefore, we found
   the key is data governance – to be able to identify who owns the data,
   really understand who uses that data and for what purposes, and come
   together as teams to make sure that we’re aligned on those definitions
   and how it’s going to be used. The key here is ownership. To really
   provide, not only the definition of “you’re the owner,” but to provide
   the capabilities and the transparency into the data through dashboards,
   so that they can monitor if they’re meeting the expectations of that
   data, now.

     The key is data governance – to be able to identify who owns the
     data, really understand who uses that data and for what purposes

   The data governance team on my team is a small team and they’re really
   teaching people how to be a data owner, how to be a data steward. We
   used to have  a backlog of issues around data accuracy, where today
   what we’re finding is because the teams are knowledgeable about how to
   address issues, as an issue comes, they form as a team [and] they are
   able to resolve the issue and the ticket is closed. So, I really think
   that one of the things to focus on in data accuracy is just around
   governance and around who owns that data and who’s accountable for it.

Data Latency

   Then, the last point I think we should consider is data latency. What
   that means is how old does can the data be before somebody uses it? In
   the beginning of our journey, six years ago, people were really using
   their current data sources –  those silos of data within their own
   manufacturing location. So, the requirements that we were getting were
   more like 24-48 hours because they were, in parallel, using our
   platform to do their analysis, but they’re making their business
   decisions based on the environments that they had at that time. As they
   became to understand the capabilities of the big data platform and the
   value it could bring in their analytics, the requirement for latency
   got smaller and smaller and smaller for each of the pipelines. So,
   we’ve had to evolve our environment to go from 24-48 hours to more like
   15 minutes-four hours. And, in order to do that we had to really think
   about how we were processing the data.

   So, again we implemented ActiveScale in our Las Vegas data center so
   that we could quickly move the data from the manufacturing site onto
   our on-premises environment in Las Vegas, and, then with the S3 object
   store to send that data to Amazon. In AWS™ we fan out the data and we
   learned a lot about our pipelines. And, we had to re-engineer several
   of our pipelines, but that was what was necessary in order for us to
   meet that service level agreement of latency with our consumers.

   Now, as we’re evolving more and more in our capabilities and maturity
   around analytics, the demands are getting even more intense and now
   they want real-time and they want near real-time. So how do you
   accomplish that in the cloud environment? That’s very difficult, so
   what we’ve now decided to do, as we have evolved our platform, is that
   we’re now implementing ActiveScale directly in each of our
   manufacturing locations so that we can actually accommodate those
   requirements of streaming data and be able to insert analytics into the
   stream of data directly on the manufacturing shop floor.

Futureproofing

   So, those (data completeness, accuracy and latency) are really the key
   things to consider. Going back to what I’ve talked about [previously] –
   futureproofing our environment to really anticipate [the future
   business] needs and figure out how your architecture, how your tools,
   technologies, how your processes can really support that scalable
   evolution.

Learn More

   Join JuneAn for two recent conversations on the topic of data:
     * Check out this ActualTech Media Panelcast where JuneAn Lanigan
       joined other panelists to discuss How Data is Changing the Face of
       IT
     * Watch the replay of this interview webinar Not All Data is Created
       Equal: Lessons Learned from a Data Mgmt Expert
     * Learn more about the ActiveScale system.

   Read more in this series:
     * Building a Data Analytics Platform? Start by Futureproofing
     * 6 Ways to Optimize the Cost of Your Big Data Platform




   ActiveScaleAnalyticsMachine LearningSmart Factory
   Editorial Team: All things data with news and insights on systems and
   technology that help you capture, preserve, access and transform your
   data.
   Related Post
    1. 6 Ways to Optimize the Cost of Your Big Data Platform
       Here are our tips and tricks about how to evaluate and optimize
       costs for a…
    2. The Industry 4.0 Transition – Architecting for AI, ML and IoT
       To fully utilize the benefits of AI and ML computing to accelerate
       the journey towards…

   This blog includes news across the Western Digital® portfolio
   including: G-Technology, SanDisk, Upthere, WD and Western Digital.

   Western Digital Technologies, Inc. is the seller of record and licensee
   in the Americas of SanDisk® products.

   CAUTIONARY STATEMENT REGARDING FORWARD-LOOKING STATEMENTS: This website
   may contain forward-looking statements, including statements relating
   to expectations for our product portfolio, the market for our products,
   product development efforts, and the capacities, capabilities and
   applications of our products. These forward-looking statements are
   subject to risks and uncertainties that could cause actual results to
   differ materially from those expressed in the forward-looking
   statements, including development challenges or delays, supply chain
   and logistics issues, changes in markets, demand, global economic
   conditions and other risks and uncertainties listed in Western Digital
   Corporation’s most recent quarterly and annual reports filed with the
   Securities and Exchange Commission, to which your attention is
   directed. Readers are cautioned not to place undue reliance on these
   forward-looking statements and we undertake no obligation to update
   these forward-looking statements to reflect subsequent events or
   circumstances.
     * PRIVACY POLICY
     * YOUR CALIFORNIA PRIVACY RIGHTS
     * TERMS AND CONDITIONS

     *
     *
     *
     *

   © 2019 Western Digital Corporation or its affiliates. All rights
   reserved. | View Non-AMP Version
   X

Your choice regarding cookies

   We use cookies to enhance the performance of our site and give you a
   great user experience.
   For More information about Privacy Click Here
   (BUTTON) Accept
   (BUTTON) Reject
   Privacy Settings

   Powered by AMPforWP

   Type your search query and hit enter: 1___________________
   ____________________ Search

   (BUTTON) X
   Navigate
     * Home
     * Data Infrastructure
     * Technology Trends
     * Company
     * Subscribe to Our Newsletter

     *
     *
     *
     *

   (BUTTON)

   (BUTTON)
   (BUTTON)

End-to-End NVMe™ is Your Future, the Only Question is When

     * Guest Blog in Applications

   Guest blog by Tony Lock, Director of Engagement & Distinguished
   Analyst, and Bryan Betts, Principal Analyst, of Freeform Dynamics Ltd

   IT has always been hit by marketing waves that speak of new systems
   that will revolutionize the way everything works. Well, in IT as in
   real life, revolutions are few and far between ⁠— and it’s the steady
   creep of technology that brings most developments into widespread use.
   But some technology advancements impact parts of the IT infrastructure
   that are so important that any new development there needs careful
   consideration. Hence the question, are you ready for NVMe?

Are you ready for NVMe?

   NVMe, the new standard for communications between servers and storage,
   offers many potential benefits over the existing widely used SAS and
   SATA. And performance is chief amongst them. But as with any new tech,
   when it first hits the streets or, more accurately, data centers, it
   arrives with a price premium. The questions usually then become: has
   the technology reached a level of maturity that justifies bringing it
   into use, and assuming it has, where does it make sense to use it
   first?

   The crucial thing here is to have an accurate picture of the workloads
   being run and their importance to the business. Without this ⁠— and of
   course, without an understanding of how their performance could differ
   using NVMe ⁠— it can be very difficult, if not impossible, to justify
   any investment.

   So where have the common starting points been for the use of NVMe so
   far? A recent study carried out by Freeform Dynamics showed that NVMe
   is most widely deployed supporting very low latency-sensitive
   transaction systems. Business-critical real-time analytics,
   data-intensive modelling and engineering were the workloads where NVMe
   was next most widely deployed, with demanding analytics workloads not
   far behind.
   Inside Track Research Note, NVMe – The State of Play, Freeform Dynamics
   Ltd, 2019

   These kinds of workloads are a perfect fit for NVMe because they
   require fast access to data, and often to very large volumes of data.
   We also saw some take-up in large-scale virtual machine and desktop
   virtualization environments, and it’s likely that usage will expand
   fairly quickly here as the price differential between NVMe and
   traditional flash platforms diminishes.

Storage Investment Woes

   For some of the current challenges in storage, making the business case
   for a budget request can be relatively straight forward, most notably
   when it comes to acquiring additional capacity. After all, if the
   storage systems are close to their limits, but users, customers and
   applications keep creating more data, there are only two choices:
   migrate data off of the storage platforms, or acquire more capacity.

   While the capabilities built into storage systems to help with data
   migration and archiving have improved greatly in recent years, asking
   to move data off active systems can generate significant user and
   business resistance. It is often simpler just to buy more storage, at
   least assuming you have the space and power to install the extra
   hardware.

   This can provide a convenient way to introduce NVMe systems into your
   computer rooms or data centers, but it will likely be a slow way to get
   NVMe widely deployed. Another big opportunity to bring NVMe into play
   will be if you have to bring in new infrastructure to support a new
   application or if an application is undergoing a major update. But
   again, NVMe adoption will be limited to how fast your organization is
   undertaking such projects.

   The main opportunity to get NVMe deployed widely and quickly will be if
   you have kit that is either reaching its financial write-off, or if
   there is funding to replace out-of-support platforms. All of these
   approaches are well understood.

The Cost of Doing Nothing

   But NVMe can provide another route through which to make the business
   case, and this involves recognizing that there are usually costs
   associated with taking the “do nothing” approach. NVMe can offer better
   performance and much lower latency for certain workloads, and improving
   service quality here can have visible business benefits.

   For example, NVMe could bring the organization measurable financial
   benefits. For example, if it enables the IT infrastructure to be more
   responsive to applications and users, this in turn can improve customer
   experience thereby increasing order conversion rates. Alternatively,
   faster IT may allow more orders to be processed or facilitate faster
   analysis of business trends, enabling near-real-time actions to be
   taken as the business environment changes.

   Some of these may not be areas that IT professionals will have explored
   in the past when making a business case for investment in storage, and
   they may be complex to quantify upfront. But as businesses look to
   become more agile and customer-centric, your storage platforms must be
   able to meet these new needs in terms of speed and responsiveness.

   And one factor that is certain to make the business case easier to
   write is the fact that the price premium that NVMe products have over
   traditional SAS/SATA platforms continues to decrease. It may eventually
   even disappear.

Your IT Ecosystem

   In the medium term and longer, NVMe usage could well expand to cover
   nearly all use-cases where users are actively engaged with data,
   especially if, as is distinctly possible, NVMe becomes standard in
   storage platforms across the board.

   But, and this is an important caveat, the potential of NVMe storage can
   only be fully exploited if the rest of the IT infrastructure supports
   it. In particular, servers and networks must be able to take advantage
   of NVMe-enabled data capabilities such as very low latency and high
   data parallelization. For once, a lack of skills is unlikely to hinder
   adoption, as for many use cases there is little need for specialist
   NVMe knowledge.

   The key to adoption, as ever, is to understand where to start. NVMe is
   now ready for the enterprise. The bigger question is, are you ready for
   NVMe? And, just as importantly, are your suppliers ready to help you
   make use of NVMe?

     Are you ready for NVMe? Are your suppliers ready to help you make
     use of NVMe?

NVMe is End-to-End

   Although much is made of NVMe’s role as the modern successor to SAS and
   SATA, in truth it is a lot more than that. Yes, it is a faster drive
   interface, with layers of software latency stripped out and no
   concessions made for legacy rotating media.

   But that’s like the early days of SSDs, where flash storage was simply
   used to emulate a hard disk. You can get a useful speed boost that way,
   but nothing like as much of a boost as you can get if you use flash as
   flash, without asking it to pretend to be something else!

   So just as flash really started to shine once it was built into devices
   such as All-Flash Arrays, with the disk metaphor largely discarded, the
   real value of NVMe will come through as we stop focusing on local
   storage and take it end-to-end.

   It’s still very useful as a local storage interface, of course, and
   NVMe storage for a server (or a PC) is relatively cheap, with a
   shrinking price-premium over the cost of a PCIe SSD of the same size.
   Increasingly, NVMe is becoming the norm for local SSD in many use
   cases. However, the reality is that in almost every aspect, an NVMe SSD
   is still just a faster local hard drive.

See the Bigger Picture

   NVMe can be so much more than that, though. Shared low-latency storage
   that bridges the performance gap between memory and disk drives enables
   whole new ways of thinking when it comes to designing and building
   applications and services. That means we need to think about the whole
   solution, not just what’s inside the server. Plus what’s inside a
   server is usually only accessible to that server (although there are
   proprietary schemes to virtualize, share and pool direct-attached
   NVMe).

   In addition, there is the question of the weakest link in the chain:
   where is it? Except in a few cases – applications that are especially
   sensitive to latency, for example – it is unlikely to be the dir
   ect-attached storage in the servers. Speeding that up might give some
   nice benefits in terms of boot speed and server performance, but in the
   main, we are not talking solid business benefits here. It’s far more
   likely that there will be a bottleneck somewhere else in the networking
   and storage infrastructure.

   There are caveats, of course, not least that when we talk about
   end-to-end NVMe we are very likely to be talking about NVMe-over-Fabric
   (NVMe-oF™), and that imposes requirements of its own. In particular, it
   may need a new or upgraded network fabric – but once that’s in place it
   is available to all servers on the network, with no need to remove the
   lid and install new cards or storage devices.

     If your current infrastructure isn’t adequate then it’s better to
     build anew wherever possible, rather than trying to expand and
     stretch what you already have in place.

   And fundamentally, as our research repeatedly shows, if your current
   infrastructure isn’t adequate then it’s better to build anew wherever
   possible, rather than trying to expand and stretch what you already
   have in place. If you can’t refresh everything in one go, put in as
   much new as you can manage, then move apps over as it becomes necessary
   and possible. Re-use what you can, of course, but renew the
   infrastructure that it sits upon so you can also bring in new hardware,
   software and systems as necessary.

   As ever, the key is to think ahead and, whenever possible, build for
   the future rather than rebuilding the past. And end-to-end NVMe should
   be part of that future, the only question is when.

Download the Research Report

   Next Read: 3 Things We Learned (the Hard Way) About Data Quality »
   Data CenterNVMeNVMe-oF
   Guest Blog: Insights and inspirations from our partners, customers &
   more.
   Related Post
    1. 4 Reasons You Should Be Excited at OCP Amsterdam
       The open-source community is pushing forward new technology to make
       hardware more flexible, scalable, and…
    2. NVMe™ Queues Explained
       NVMe offers parallel and scalable interface designed to reduce
       latencies, increase IOPS and bandwidth thanks…

   This blog includes news across the Western Digital® portfolio
   including: G-Technology, SanDisk, Upthere, WD and Western Digital.

   Western Digital Technologies, Inc. is the seller of record and licensee
   in the Americas of SanDisk® products.

   CAUTIONARY STATEMENT REGARDING FORWARD-LOOKING STATEMENTS: This website
   may contain forward-looking statements, including statements relating
   to expectations for our product portfolio, the market for our products,
   product development efforts, and the capacities, capabilities and
   applications of our products. These forward-looking statements are
   subject to risks and uncertainties that could cause actual results to
   differ materially from those expressed in the forward-looking
   statements, including development challenges or delays, supply chain
   and logistics issues, changes in markets, demand, global economic
   conditions and other risks and uncertainties listed in Western Digital
   Corporation’s most recent quarterly and annual reports filed with the
   Securities and Exchange Commission, to which your attention is
   directed. Readers are cautioned not to place undue reliance on these
   forward-looking statements and we undertake no obligation to update
   these forward-looking statements to reflect subsequent events or
   circumstances.
     * PRIVACY POLICY
     * YOUR CALIFORNIA PRIVACY RIGHTS
     * TERMS AND CONDITIONS

     *
     *
     *
     *

   © 2019 Western Digital Corporation or its affiliates. All rights
   reserved. | View Non-AMP Version
   X

Your choice regarding cookies

   We use cookies to enhance the performance of our site and give you a
   great user experience.
   For More information about Privacy Click Here
   (BUTTON) Accept
   (BUTTON) Reject
   Privacy Settings

   Powered by AMPforWP

   Type your search query and hit enter: 1___________________
   ____________________ Search

   (BUTTON) X
   Navigate
     * Home
     * Data Infrastructure
     * Technology Trends
     * Company
     * Subscribe to Our Newsletter

     *
     *
     *
     *

   (BUTTON)

   (BUTTON)
   (BUTTON)

Overcoming Storage Performance and Capacity Challenges in Video Production
and Surveillance

     * Dave Montgomery in Industries

   It is impossible to ignore the storage trajectory for the Media &
   Entertainment (M&E) industry, as well as Surveillance industries, with
   new use cases emerging more frequently than ever before. Applications,
   such as virtual reality, 4K video (going to 8K and beyond), and
   advances in animation technology, are forcing M&E production workflows
   to handle massive amounts of data. And, in the surveillance industry,
   pattern detection, more cameras, higher frame rates, and increasing
   retention times are straining today’s infrastructure.

Is Your Infrastructure Future Ready?

   This constantly evolving environment is overwhelming traditional
   servers and storage, and standard “whitebox” configurations can quickly
   become bottlenecks. To overcome today’s challenge and ensure your
   infrastructure is “future ready” for these inevitable advancements,
   organizations must pay close attention to how their infrastructure,
   including the data center and edge, is designed to meet the
   ever-evolving performance, scalability, and density demands.

From Silicon to Systems: How Western Digital is Helping Future Ready Your
Infrastructure

   Western Digital is already a storage leader in both M&E and
   surveillance – with well over $1B per year in business in these
   industries. From our WD Purple® branded devices – explicitly designed
   for video files – to our G-Technology™ high-performance solutions for
   intensive video editing, and through our storage servers and platforms,
   we have possibly the broadest portfolio in the industry.

   We recently introduced two new additions to our Data Center Systems
   portfolio – ideally suited for M&E and surveillance applications. The
   Ultrastar® Serv24-4N four-node NVMe™ all-flash and the Ultrastar®
   Serv24+6 hybrid storage servers. These servers bring new levels of
   performance, scalability, and density for cost-sensitive surveillance
   and M&E environments.

   The Ultrastar Serv24-4N NVMe storage server combines the speed of NVMe
   SSDs with a quad-server architecture to deliver a “cluster-in-a-box.”
   Featuring the latest Intel^® Xeon^® CPUs and chipset, core count and
   power can be selected to optimize data workload and datacenter
   efficiency requirements. NVMe technology, along with non-blocking PCIe
   lanes, allow the full potential of flash storage to be realized. It is
   a perfect match for those M&E workoads requiring massive compute power
   with adjacent high-performance flash storage.

   The Ultrastar Serv24+6 Hybrid Storage Server is a powerful high-density
   hybrid (flash and disk) storage server featuring up to 420TB of raw
   storage, a flash acceleration tier with NVMe SSDs, and up to 28-core
   dual Intel Xeon Scalable Processor CPUs. It is an ideal fit for
   data-intensive applications in surveillance or software-defined storage
   environments.

   These servers can help you turbocharge your M&E or surveillance
   applications. Whether you need to support high performance video
   production applications or require massive HDD capacity, with a flash
   tier, in a compact package, Western Digital is bringing new levels of
   performance, scalability, and density for cost-sensitive video and
   surveillance environments.

Learn More!

   We inivte you to join us for our webinar titled “How to Overcome
   Storage Performance and Capacity Challenges in Video Production and
   Management” on Wednesday, October 9, at 10:00am Pacific Time, where
   we’ll dive into why standard “whitebox” configurations can quickly be
   overwhelmed, How flexible and scalable storage servers can improve
   production and management of the most demanding applications, and share
   more on the two Western Digital products mentioned above.

   Also, if you are headed to NAB in New York on October 16-17, stop by
   our booth (#N928) to learn more about how our newest portfolio
   offerings were designed to address some of today’s greatest video
   workload challenges.
   Next Read: End-to-End NVMe™ is Your Future, the Only Question is When »
   Flash StorageMedia and EntertainmentMedia ProductionSurveillanceVideo
   Dave Montgomery: Dave is Director of Storage Platform Marketing with
   20+ years of experience in the enterprise storage, computing, and
   software business.
   Related Post
    1. From Abstraction to Visualization – Tackling Data in New Media
       Workflows
       From abstraction to visualization, making sense of the content
       across various platforms and formats is…
    2. What’s Hot at NAB 2019
       NAB 2019 is just around the corner, and as every year, I want to
       take…

   This blog includes news across the Western Digital® portfolio
   including: G-Technology, SanDisk, Upthere, WD and Western Digital.

   Western Digital Technologies, Inc. is the seller of record and licensee
   in the Americas of SanDisk® products.

   CAUTIONARY STATEMENT REGARDING FORWARD-LOOKING STATEMENTS: This website
   may contain forward-looking statements, including statements relating
   to expectations for our product portfolio, the market for our products,
   product development efforts, and the capacities, capabilities and
   applications of our products. These forward-looking statements are
   subject to risks and uncertainties that could cause actual results to
   differ materially from those expressed in the forward-looking
   statements, including development challenges or delays, supply chain
   and logistics issues, changes in markets, demand, global economic
   conditions and other risks and uncertainties listed in Western Digital
   Corporation’s most recent quarterly and annual reports filed with the
   Securities and Exchange Commission, to which your attention is
   directed. Readers are cautioned not to place undue reliance on these
   forward-looking statements and we undertake no obligation to update
   these forward-looking statements to reflect subsequent events or
   circumstances.
     * PRIVACY POLICY
     * YOUR CALIFORNIA PRIVACY RIGHTS
     * TERMS AND CONDITIONS

     *
     *
     *
     *

   © 2019 Western Digital Corporation or its affiliates. All rights
   reserved. | View Non-AMP Version
   X

Your choice regarding cookies

   We use cookies to enhance the performance of our site and give you a
   great user experience.
   For More information about Privacy Click Here
   (BUTTON) Accept
   (BUTTON) Reject
   Privacy Settings

   Powered by AMPforWP

   Type your search query and hit enter: 1___________________
   ____________________ Search

   (BUTTON) X
