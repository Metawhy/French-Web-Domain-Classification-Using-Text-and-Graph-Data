   Aller au contenu principal

   Sites Inria
     * Institut
     * Sujets de société
     * Culture scientifique
     * Alumni

   Inriality logo

Inriality

Partager toutes
les réalités du numérique avec Inria

Formulaire de recherche

   Recherche _______________
   Recherche

Thématiques

     * #agriculture
     * #communication
     * #culture & loisirs
     * #économie & commerce
     * #éducation
     * #environnement
     * #habitat & urbanisme
     * #industries
     * #informatique
     * #santé
     * #transport
     * #vie citoyenne

Menu mobile

     * #Thématiques

     * Articles
     * Dossiers
     * Proposer un sujet

   #agriculture
   #communication
   #culture & loisirs
   #économie & commerce
   #éducation
   #environnement
   #habitat & urbanisme
   #industries
   #informatique
   #santé
   #transport
   #vie citoyenne

Formulaire de recherche

   Recherche _______________
   Recherche

Queue 'slideshow'

   Facebook Twitter
   Articles // Le 10.07.2018

Tout comprendre sur la blockchain

   « Révolution », « nouvel Internet », « remise en cause des fondements
   de notre société ». Voilà quelques-uns des termes employés dans les
   médias pour définir la blockchain, véritable buzzword depuis plusieurs
   mois. Mais qu'est-ce que la blockchain, ses réalités techniques,
   sociales et ses enjeux ?...
   Par : Dominique Fidel - Citizen Press
   Facebook Twitter
   Articles // Le 19.06.2018

Des campagnes toujours plus connectées

   Paupérisation, perte du lien social, isolement géographique et
   culturel… Depuis dix ans, l'arrivée du numérique change
   considérablement la donne, tissant des liens nouveaux et ouvrant la
   porte à des usages inédits, principalement dans le domaine du travail
   et de la santé.
   Par : Dominique Fidel - Citizen Press
   Facebook Twitter
   Articles // Le 17.05.2018

2067, la singularité ou l'empire des machines

   [Copublication] La singularité, définie comme le moment où
   l'intelligence artificielle atteint le niveau de l'intelligence
   humaine, fait l'objet de multiples questionnements. Est-elle possible,
   souhaitable, inévitable ? Alors que robots et logiciels "intelligents"
   s'immiscent dans nos vies et notre...
   Par : Cyril Fiévet - Usbek & Rica
   Facebook Twitter
   Articles // Le 09.04.2018

Quand la culture fait sa révolution numérique

   Musée 100 % numérique, modélisation 3D, géolocalisation, Web
   sémantique, réalité augmentée, indexation de vidéos…. Les sciences du
   numérique ont littéralement envahi la sphère de la culture et des arts
   depuis les vingt dernières années. Et nombreuses et nombreux sont les
   artistes qui ont choisi de...
   Par : Stéphanie Salti - Citizen Press
     * Articles
     * Dossiers
     * Proposer un sujet

Derniers articles

   Tout savoir sur la blockchain

Tout comprendre sur la blockchain

   Des campagnes de plus en plus connectées

Des campagnes toujours plus connectées

2067, la singularité ou l'empire des machines

Quand la culture fait sa révolution numérique

   Code de programmation

2067, la mémoire dans la peau

Nouvelles énergies : la planète 3.0

2067 ou la disparition des interfaces humains-machines (partie 2)

2067 ou la disparition des interfaces humains-machines (partie 1)

   Bienvenue en Cybercratie

En 2067, le gouvernement parfait ?

2067, des robots dans la ville

Une vie numérique éternelle en 2067 ?

Quand l’énergie devient intelligente

     * Voir plus d'articles
     *

Inriality sur Facebook

Suivez-nous sur twitter

   Loading Tweets

Thématiques

   agriculture
   communication
   culture & loisirs
   économie & commerce
   éducation
   environnement
   habitat & urbanisme
   industries
   informatique
   santé
   transport
   vie citoyenne

Contenus

     * Articles
     * Dossiers
     * Proposer un sujet

Ils en parlent...

La Fonderie

   La Fonderie, agence numérique d’Île-de-France.

Futurapolis [Le Point]

   Futurapolis rend compte des innovations dans les grands domaines de la
   vie quotidienne.

Suivez-nous sur :

     * Facebook
     * Twitter
     * Pinterest
     * YouTube
     * Flux RSS

Propulsé par

   Inriality est propulsé par l'institut de recherche en sciences du
   numérique, Inria.

Liens utiles

     * Qui sommes-nous
     * Plan du site
     * Contact
     * Glossaire
     * Crédits et mentions légales
     * Espace presse
   Aller au contenu principal

   Sites Inria
     * Institut
     * Sujets de société
     * Culture scientifique
     * Alumni

   Inriality logo

Inriality

Partager toutes
les réalités du numérique avec Inria

Formulaire de recherche

   Recherche _______________
   Recherche

Thématiques

     * #agriculture
     * #communication
     * #culture & loisirs
     * #économie & commerce
     * #éducation
     * #environnement
     * #habitat & urbanisme
     * #industries
     * #informatique
     * #santé
     * #transport
     * #vie citoyenne

Menu mobile

     * #Thématiques

     * Articles
     * Dossiers
     * Proposer un sujet

   #agriculture
   #communication
   #culture & loisirs
   #économie & commerce
   #éducation
   #environnement
   #habitat & urbanisme
   #industries
   #informatique
   #santé
   #transport
   #vie citoyenne

Formulaire de recherche

   Recherche _______________
   Recherche
   Le 13.11.2013
   Par : Martin Hachet et Martin Bellet

Interaction Hommes-Machines : une histoire de 30 ans

   22 décembre 1980, Antenne 2 consacre un reportage à une science alors
   balbutiante : l’interaction Homme-Machine. 30 ans plus tard, Martin
   Hachet, chercheur Inria Bordeaux, commente pour nous ces images.
    Partager Tweet Partager Envoyer
   Le Buroviseur Inria

Vers des écrans tactiles (vidéo à 1’46)

   « Inria, en la personne de Jean-Claude Sperandio, conseiller
   scientifique en ergonomie, avait déjà une vision pertinente de
   l’avenir, car les écrans tactiles allaient connaître un boom
   extraordinaire, accéléré par la sortie de l’iPhone en 2007. Une grande
   partie des activités de recherche se sont alors réorientés vers les
   nouveaux types d’interaction rendu possible par cette technologie. Le
   tactile accompagne aussi la montée en puissance des tablettes, au
   détriment des ordinateurs standard dont les ventes diminuent. Pour
   autant, cette technologie ne va pas remplacer le clavier et la souris,
   il s’agit d’une solution additionnelle offerte à l’utilisateur. La
   prochaine étape, est de faire disparaître les écrans que l’on connaît
   dans l’environnement réel qui nous entoure (voir encadré). »


   IFRAME:
   http://player.ina.fr/player/embed/CAB8001676901/1/1b0bd203fbcd702f9bc9b
   10ac3d0fc21/560/315/1/148db8

   [Ergonomie de l'informatique] - une vidéo de l'INA

Parler à la machine (vidéo à 2’10)

   « Premier constat, la reconnaissance vocale fonctionne. C’est à nouveau
   l’iPhone qui s’en est emparé, mais avec un succès moindre. Si de
   nombreuses techniques de communication vocale avec une machine
   existent, je ne pense pas que cela va révolutionner l’IHM. Aujourd’hui,
   l’acceptation de cette technologie par les utilisateurs me semble
   encore limitée. Je pense qu’il faut garder la voix pour de la
   communication entre humains, et privilégier d’autres canaux, comme le
   tactile, pour interagir avec une machine. »

Etudier le regard (vidéo à 2’35)

   « Comme le montre ce reportage, l’informatique a su intégrer très tôt
   le facteur humain dans son développement. Ce grand principe de l’IHM –
   imaginer des interfaces adaptées à l’utilisateur et non l’inverse – est
   encore aujourd’hui notre principale préoccupation : je me retrouve
   totalement dans cette démarche. Nous mesurons par exemple l’activité
   cérébrale d’une personne afin d’adapter certains paramètres
   d’interaction en fonction de l’utilisateur. J’ai l’impression d’être
   encore un pionnier, je m’identifie donc complètement aux chercheurs de
   l’époque. Notre science est très jeune, et il reste beaucoup à faire. »


   Demain : interagir en 3D

   « Jusqu'à une période récente, physique et numérique étaient deux
   univers séparés, souligne Martin Hachet. Mais les lignes sont en train
   de bouger, avec la montée en puissance de la réalité augmentée, et des
   imprimantes 3D, qui permettent de créer physiquement des objets
   numériques. »

   Améliorer la manipulation de ces objets via des méthodes d’interaction
   adaptées est donc devenu un enjeu majeur pour les membres de l’équipe
   projet POTIOC d’Inria Bordeaux, que dirige Martin Hachet. Leur dernière
   innovation : Toucheo, un dispositif qui combine écran tactile
   multitouch et visualisation stéréoscopique d'objets en trois
   dimensions. Conçu en collaboration avec la PME Immersion, cette
   solution originale offre des fonctionnalités inédites à l’utilisateur,
   comme la manipulation pseudo-directe d’objets qui « flottent »
   au-dessus des mains, ce qui favorise une bonne visualisation des objets
   tout en assurant une interaction simple et efficace.


   A lire sur ce sujet & sur Inriality : Arrêtez de regarder la 3D,
   prenez-en le contrôle !


   Mots-clé :
   #le saviez-vous
   / #informatique
   / #Interface Homme-Machine
   / #Inria
   / #sciences du numérique
   / #interaction homme-machine
   Martin Hachet et Martin Bellet
   A propos
   Martin Hachet
   Martin Hachet est un chercheur Inria qui dirige l'équipe Potioc. Ses
   activités de recherche concernent les problèmes d'interaction entre des
   utilisateurs et des systèmes interactifs. En particulier, il est
   spécialiste dans le domaine de l'interaction avec des environnements 3D
   dans différents contextes d'utilisation, depuis les dispositifs
   mobiles...
   En savoir plus sur ce contributeur
   Martin Bellet
   Après des études d'ingénieurs, je me tourne vers ma première passion:
   l'écriture. J'ai fini des études de scénariste et je travaille au
   développement de différents projets (long métrage, série, roman...)En
   parallèle, je travaille aussi comme journaliste, je suis actuellement
   responsable d'édition.
   En savoir plus sur ce contributeur

Plus d’informations sur le sujet ?

   Oscar, personnage virtuel

Découvrez Oscar, le personnage...

2067 ou la disparition des...

   L’écran qui lit en vous

L’écran qui lit en vous

Les derniers articles

Tout comprendre sur la blockchain

   Tout savoir sur la blockchain
   Lire

Des campagnes toujours plus connectées

   Des campagnes de plus en plus connectées
   Lire

Thématiques

   agriculture
   communication
   culture & loisirs
   économie & commerce
   éducation
   environnement
   habitat & urbanisme
   industries
   informatique
   santé
   transport
   vie citoyenne

Contenus

     * Articles
     * Dossiers
     * Proposer un sujet

Ils en parlent...

La Fonderie

   La Fonderie, agence numérique d’Île-de-France.

Futurapolis [Le Point]

   Futurapolis rend compte des innovations dans les grands domaines de la
   vie quotidienne.

Suivez-nous sur :

     * Facebook
     * Twitter
     * Pinterest
     * YouTube
     * Flux RSS

Propulsé par

   Inriality est propulsé par l'institut de recherche en sciences du
   numérique, Inria.

Liens utiles

     * Qui sommes-nous
     * Plan du site
     * Contact
     * Glossaire
     * Crédits et mentions légales
     * Espace presse
   Aller au contenu principal

   Sites Inria
     * Institut
     * Sujets de société
     * Culture scientifique
     * Alumni

   Inriality logo

Inriality

Partager toutes
les réalités du numérique avec Inria

Formulaire de recherche

   Recherche _______________
   Recherche

Thématiques

     * #agriculture
     * #communication
     * #culture & loisirs
     * #économie & commerce
     * #éducation
     * #environnement
     * #habitat & urbanisme
     * #industries
     * #informatique
     * #santé
     * #transport
     * #vie citoyenne

Menu mobile

     * #Thématiques

     * Articles
     * Dossiers
     * Proposer un sujet

   #agriculture
   #communication
   #culture & loisirs
   #économie & commerce
   #éducation
   #environnement
   #habitat & urbanisme
   #industries
   #informatique
   #santé
   #transport
   #vie citoyenne

Formulaire de recherche

   Recherche _______________
   Recherche
   Le 16.01.2017
   Par :
   Cyril Fiévet - Usbek & Rica

Tout savoir (ou presque) sur les messageries chiffrées

   [Copublication] Comme le résumait Gizmodo en juin dernier, « Il n’y a
   jamais eu un meilleur moment pour commencer à chiffrer vos messages et
   appels téléphoniques. » Face aux pirates omniprésents et à la
   surveillance généralisée des communications, « le chiffrement peut vous
   protéger ». Dont acte. Les messageries chiffrées sont désormais légion.
   Pourquoi et comment les utiliser ? Suivez le guide.
    Partager Tweet Partager Envoyer

   Prenez un bon scandale, lancé par un ancien agent de la CIA, révélant
   l’ampleur et la puissance de la surveillance mondiale des réseaux,
   opérée par plusieurs agences gouvernementales à l’encontre des
   citoyens. Saupoudrez de quelques fuites savamment médiatisées,
   affectant si possible des stars et people, et exposant des détails
   juteux de leurs conversations privées, messages salaces et vidéos
   coquines à l’appui. Ajoutez-y une pincée de bugs incroyables, comme la
   faille de sécurité découverte en juin 2016 sur Facebook Messenger, qui
   permettait plutôt aisément à un hacker de modifier tout l’historique
   d’une conversation. Et vous comprendrez comment cette recette
   infaillible a donné naissance à la vague des messageries chiffrées.
   Celles-ci se comptent aujourd’hui par dizaines et n’ont d’autre
   ambition que de garantir la confidentialité et le respect de la vie
   privée des internautes, en rendant leurs conversations théoriquement
   inviolables.

Pourquoi des messageries chiffrées ?

   La réaction « Je ne suis pas un terroriste, je n’ai rien à cacher » a
   vécu. L’importance prise par les réseaux, Internet et mobiles, justifie
   désormais largement la volonté de conserver nos échanges privés, même
   si ces échanges n’ont rien de répréhensible ou d’inapproprié. Le
   caractère privé des conversations de personne à personne est un droit,
   et les messageries chiffrées ne sont qu’un outil facilitant l’exercice
   de ce droit. Mais l’usage de ces messageries se justifie aussi pour
   deux raisons.

   La première est la nature des données que nous échangeons. Comme le
   souligne Andra Zaharia sur le blog de Heimdal Security, les données qui
   transitent via chat ou SMS sont très loin de se borner à des « T’es où
   ? », « Tu fais quoi ? » et autres « LOL ». En fait, on y trouve des
   photos, des adresses email, des adresses postales, des données de
   géolocalisation, des préférences personnelles, des documents officiels
   scannés, des numéros de téléphone, des codes d’authentification à deux
   facteurs et autres identifiants bancaires. Une mine d’or pour un
   hacker. Un cauchemar potentiel pour l’utilisateur qui n’aurait pas
   saisi la possible nocuité d’envoyer ce type d’informations sur des
   cartes postales (car c’est bien à cela que s’apparente une messagerie
   non-chiffrée).

   La seconde raison tient à l’utilisation qui est faite de ces données,
   non par des pirates mal intentionnés, mais par les fournisseurs de
   services (et leurs clients et annonceurs) eux-mêmes. La plupart des
   réseaux sociaux sont d'usage gratuit et ont recours au principe du
   ciblage publicitaire.

     Plus vous parlez, plus vous échangez, plus vous montrez, et plus
     ciblé vous serez.

   Avez-vous vraiment envie d’être bombardé de publicités de
   réfrigérateurs, juste pour avoir mentionné plusieurs fois le mot frigo
   dans vos messages ? Et avez-vous vraiment envie que l’ensemble de vos
   messages - toutes les conversations, toutes les photos, le moindre de
   vos emojis - soient stockés jusqu’à la nuit des temps sur des serveurs
   distants, où ils seront analysés sans relâche par des outils chaque
   jour plus affutés et plus intelligents ?

   C’est bien de cela qu'il s’agit aussi. Fin septembre 2016, peu après la
   livraison par Google de sa nouvelle messagerie Allo, Edward Snowden,
   encore lui, réagissait vertement. « Google Surveillance, c’est Allo. Ne
   l’utilisez pas », twittait-il. De fait, Allo propose bien du
   chiffrement, mais pas par défaut. Et les messages des utilisateurs sont
   effectivement conservés par Google, sans limitation de durée,
   officiellement afin d’optimiser le fonctionnement de la messagerie. «
   Un pot de miel pour les agences de renseignement », comme le jugeait
   The Next Web.

Comment fonctionne le chiffrement ?

   Les messageries offrant la meilleure sécurité utilisent des procédés de
   chiffrement de bout en bout ("End-to-end Encryption", ou E2EE).
   Concrètement, cela signifie que tout ce qui est émis (depuis un
   smartphone ou un ordinateur) est chiffré à la source, envoyé, puis
   déchiffré une fois parvenu à destination. En principe, le procédé
   assure une parfaite confidentialité des échanges, empêchant en
   particulier les écoutes de la part du fournisseur d’accès ou opérateur
   télécom. Tout ce qui transite via les réseaux est illisible pour qui ne
   possède pas les clés cryptographiques correspondantes.

   En pratique, cette inviolabilité demeure théorique. Il est toujours
   possible pour le développeur d’une messagerie d’introduire des
   "backdoors" (portes dérobées), utilisables au besoin par les autorités
   pour accéder aux messages. Et si les techniques de E2EE assurent bien
   que les échanges sont sécurisés entre deux points, le piratage demeure
   possible, via une attaque de type "attaque de l’homme du milieu" ("Man
   in the middle", ou MITM). Dans ce cas, un individu mal intentionné peut
   parvenir à se faire passer pour le destinataire et ainsi recevoir le
   message qui lui était destiné, avant de réencoder le message pour le
   faire suivre, sans laisser de trace de l’interception. Le procédé
   demeure très complexe à mettre en œuvre et on peut admettre que
   beaucoup des messageries chiffrées de bout en bout offrent un niveau de
   protection très satisfaisant pour l’usager lambda.

   Deux précautions sont toutefois à prendre en optant pour une messagerie
   chiffrée. La première est de s’assurer que l’on parle bien de E2EE :
   certains outils proposent du chiffrement, mais pas de bout en bout, et
   sont ainsi plus vulnérables. La seconde est de vérifier le caractère
   systématique du chiffrement : plusieurs messageries offrent bien cette
   fonctionnalité, mais pas par défaut – c’est une option que
   l’utilisateur doit activer.

Qu’en pensent les gouvernements ?

   Sans surprise, les autorités ne voient pas forcément d’un bon œil la
   généralisation des messageries chiffrées, dont on sait qu’elles sont
   (et seront) – aussi – utilisées pour toutes formes d’activités
   criminelles (comme le sont toutes les innovations technologiques depuis
   la nuit des temps, de la traction avant au smartphone, en passant par
   Internet).

   Le sujet a fait couler de l’encre ces dernières années, et même tout
   récemment. Rob Bertholee, chef des services secrets hollandais, a fait
   réagir en septembre en arguant que l’existence des messageries
   chiffrées compliquait encore la lutte contre le terrorisme pour les
   gouvernements. Des déclarations plutôt mal reçues dans son pays, qui
   avait précisément adopté en début d’année une posture officielle
   claire, opposée « à toute forme de restriction dans le développement,
   la disponibilité et l’usage de la cryptographie. »

   En France, le premier ministre Bernard Cazeneuve a annoncé en août 2016
   (puis en septembre) son intention de lancer « une initiative européenne
   contre le chiffrement », remettant à l’ordre du jour le débat sur la
   nécessité pour les éditeurs de messageries chiffrées d’inclure dans
   leurs outils des "backdoors" permettant aux autorités, au besoin,
   d’accéder aux messages.

   Un principe qui n’est ni très réaliste, ni très bien vu des experts, et
   encore moins des défenseurs du respect de la vie privée.

   « On ne peut pas affaiblir le chiffrement "juste un petit peu, pour de
   bonnes causes" », explique par exemple l’organisation hollandaise de
   défense des libertés numériques Bits of Freedom, après avoir insisté
   sur le fait que « le respect de la vie privée et l’utilisation de la
   cryptographie sont au cœur d’une société libre et garantissant la
   sécurité de ses citoyens. »

   C’est bien le cœur du débat : soit une messagerie est (correctement)
   chiffrée, pour fournir aux usagers une confidentialité légitime (et
   totale) dans leurs échanges privés, soit elle ne l’est pas (et n’offre
   donc aucune garantie réelle et pérenne).

   C’est du reste l’opinion même exprimée par l’Agence nationale française
   de la sécurité des systèmes d’information (ANSSI), dont le directeur
   général, dans un mémo interne daté de mars 2016 et publié par
   Libération en août, s’opposait fortement à tout « affaiblissement des
   mécanismes cryptographiques », en particulier via des backdoors. Il
   écrivait :

     Cet affaiblissement généralisé serait attentatoire à la sécurité
     numérique et aux libertés de l’immense majorité des utilisateurs
     respectueux des règles tout en étant rapidement inefficace vis-à-vis
     de la minorité ciblée.

   Si l’on ajoute que les messageries ne sont que l’un des aspects du
   problème, qu’il faudra aussi compter avec d’autres procédés d’échanges
   de données (comme des réseaux alternatifs formant un Web décentralisé,
   anonyme et sans serveur, Zeronet par exemple), avec de nouveaux
   protocoles (comme BitMessage) ou avec les cryptomonnaies (dont
   certaines, orientées vers l’anonymat, intègrent par défaut l’échange de
   messages chiffrés, ShadowCash ou XDN par exemple), on mesure l’ampleur
   de la question.

   Et l’on peut admettre que toute volonté de "brider" les messageries
   chiffrées, ou d’y conserver des droits d’entrée privilégiés, est au
   mieux un combat d’arrière-garde, au pire une tentative irréaliste de
   lutter contre une évolution technique et sociale qui paraît
   inéluctable.

   Une co-publication Inria - Usbek & Rica

   Quelques messageries chiffrées à considérer

Les poids lourds

   Whatsapp. La plus populaire des messageries mobiles, qui revendique un
   milliard d’utilisateurs, a été l’une des premières à adopter le
   chiffrement de bout en bout, et sa réputation n’est plus à faire en la
   matière. Seul bémol, la messagerie, absorbée (à prix d’or) par
   Facebook, doit parfois se plier aux exigences de sa maison-mère. En
   août 2016, Facebook déclenchait un tollé mondial en annonçant que
   certaines données issues de Whatsapp (relatives aux usages mais non aux
   messages) lui seraient désormais envoyées. Plusieurs pays, comme
   l’Allemagne et l’Inde, ont fermement exigé en septembre dernier que ce
   ne soit pas le cas.

   iMessage. La messagerie Apple a de longue date généralisé le
   chiffrement de bout en bout. Elle utilise un protocole propriétaire
   offrant un niveau de protection correct, mais que plusieurs experts
   jugent néanmoins insuffisant (notamment du fait que les messages
   chiffrés, délivrés ou non, sont stockés dans le cloud pour des durées
   non négligeables).


Les valeurs sures

   Signal. De l’avis général (et surtout de celui des experts en
   sécurité), Signal est la plus irréprochable des messageries chiffrées.
   Elle est aussi l’une des plus anciennes, et quasiment celle qui définit
   les standards en matière de protection de la vie privée. Les protocoles
   développés par l’entreprise qui produit Signal sont d’ailleurs utilisés
   par d’autres, notamment WhatsApp, qui a terminé en avril 2016 leur
   intégration “pour toutes les formes de communication”. En outre, Signal
   refuse de livrer les méta-données de ses utilisateurs quand les
   autorités le lui demandent.

   Bleep. Développée par BitTorrent, l’entreprise à l’origine du protocole
   éponyme (le plus utilisé aujourd’hui pour les échanges de fichiers
   P2P), la messagerie Bleep traite très sérieusement la confidentialité
   des échanges : chiffrement de bout en bout, possibilité de “murmurer”
   des messages qui s’auto-détruisent après avoir été lus, et aucune
   donnée (ou méta-donnée) stockée dans le cloud.


Celles qui gagnent à être connues

   Wire. Développé en Suisse sous la houlette de l’un des fondateurs de
   Skype, Wire propose des fonctions attractives : chiffrement de bout en
   bout et multi-plate-formes, y compris pour les conversations de groupe,
   partage sécurisé de la géolocalisation, le tout avec un outil
   OpenSource, sans profiling ou publicité.

   Wickr. Une autre option solide, déclinée en deux versions, pour un
   usage personnel ou professionnel. L’entreprise est particulièrement
   transparente quant aux techniques et protocoles utilisés pour garantir
   la confidentialité des échanges, avec plusieurs niveaux de chiffrement
   (empêchant en principe les attaques “Man in the middle”), tant pour les
   messages en transit que stockés.


   Mots-clé :
   #le saviez-vous
   / #informatique
   / #cryptograhie
   / #données personnelles
   / #vie privée
   Cyril Fiévet - Usbek & Rica

Plus d’informations sur le sujet ?

   Une (trop) brève histoire d’Alan Turing

Une (trop) brève histoire d’Alan...

Découvrir le dossier

   Cybersécurité

Les derniers articles

Tout comprendre sur la blockchain

   Tout savoir sur la blockchain
   Lire

Des campagnes toujours plus connectées

   Des campagnes de plus en plus connectées
   Lire

Thématiques

   agriculture
   communication
   culture & loisirs
   économie & commerce
   éducation
   environnement
   habitat & urbanisme
   industries
   informatique
   santé
   transport
   vie citoyenne

Contenus

     * Articles
     * Dossiers
     * Proposer un sujet

Ils en parlent...

La Fonderie

   La Fonderie, agence numérique d’Île-de-France.

Futurapolis [Le Point]

   Futurapolis rend compte des innovations dans les grands domaines de la
   vie quotidienne.

Suivez-nous sur :

     * Facebook
     * Twitter
     * Pinterest
     * YouTube
     * Flux RSS

Propulsé par

   Inriality est propulsé par l'institut de recherche en sciences du
   numérique, Inria.

Liens utiles

     * Qui sommes-nous
     * Plan du site
     * Contact
     * Glossaire
     * Crédits et mentions légales
     * Espace presse
   Aller au contenu principal

   Sites Inria
     * Institut
     * Sujets de société
     * Culture scientifique
     * Alumni

   Inriality logo

Inriality

Partager toutes
les réalités du numérique avec Inria

Formulaire de recherche

   Recherche _______________
   Recherche

Thématiques

     * #agriculture
     * #communication
     * #culture & loisirs
     * #économie & commerce
     * #éducation
     * #environnement
     * #habitat & urbanisme
     * #industries
     * #informatique
     * #santé
     * #transport
     * #vie citoyenne

Menu mobile

     * #Thématiques

     * Articles
     * Dossiers
     * Proposer un sujet

   #agriculture
   #communication
   #culture & loisirs
   #économie & commerce
   #éducation
   #environnement
   #habitat & urbanisme
   #industries
   #informatique
   #santé
   #transport
   #vie citoyenne

Formulaire de recherche

   Recherche _______________
   Recherche
   Le 21.06.2017
   Par :
   Cyril Fiévet - Usbek & Rica

“I know kung-fu” - Apprendre en 2067

   [Copublication] Pourra-t-on un jour apprendre – à jouer du piano, à
   piloter un avion, à parler une langue étrangère – de façon automatique
   et quasi instantanée, en agissant directement sur le cerveau ?
    Partager Tweet Partager Envoyer
   En 1999, le premier volet de la trilogie Matrix (des frères Wachowski)
   illustrait le concept d’une façon qui allait marquer les esprits : via
   une prise branchée à la base de son crâne, Keanu Reeves apprenait la
   pratique du kung-fu en quelques secondes, évitant une démarche longue
   et fastidieuse (mais enrichissante), au profit d’une méthode
   “pousse-bouton”.

Apprendre... ou plus la peine ?

   “Le procédé décrit dans Matrix ne me semble pas du tout théoriquement
   impossible”, confie Giulio Ruffini, Président de Neuroelectrics,
   entreprise spécialisée depuis 2011 dans la neuro-stimulation
   électrique. “Je crois qu’il sera un jour possible d’introduire
   rapidement et directement des souvenirs dans un cerveau humain. Selon
   le modèle actuel, la mémoire est stockée via des schémas de connexions
   synaptiques des neurones. Il semble possible en principe de modifier
   ces schémas ou de remplacer des ensembles de neurones par des moyens
   artificiels, si l’on est capable de développer des interfaces
   appropriées ”, avance-t-il.

   Si un tel procédé était possible, les conséquences, tellement profondes
   qu’elles en donnent le tournis, affecteraient tous les domaines de la
   vie et de la société humaine.

   Apprendre à lire, à compter, à mémoriser des dates historiques n’aurait
   plus aucun sens. Tous les élèves, dès le plus jeune âge,
   bénéficieraient d’un socle de connaissance universel. Un peu comme un
   “vaccin de connaissance“ qu’on reçoit au plus jeune âge et qui vous
   protège le reste de votre vie.

   Instituteurs et professeurs, devenus autant d’intermédiaires inutiles,
   disparaîtraient, au profit des nouveaux maîtres que seraient les
   “éditeurs de contenu pour cerveaux vierges“. Livres et manuels
   scolaires de demain ne seraient plus des supports de cours, ils
   deviendraient l’enseignement tout entier. Eh Google, apprends-moi la
   physique quantique !

   Loisirs et culture n’auraient plus le même sens. Qui prendrait le temps
   de lire un livre, quand on peut ingérer une bibliothèque entière ? Ce
   matin, j’ai lu tout Victor Hugo.

   Dans le monde du travail, les transformations seraient tout aussi
   vastes. L’expression “formation continue“ prendrait un tout autre sens.
   Les entreprises ne recruteraient plus des talents ou des experts dans
   un domaine particulier, mais s’attacheraient seulement aux capacités
   mentales et physiques de leurs futurs employés. Poste urgent à
   pourvoir, aucune connaissance ou expérience requise, parfaites
   connexions synaptiques indispensables.

   Pour le coup, le “temps de cerveau disponible“ deviendrait une
   véritable valeur, voire une monnaie d’échange universelle. Même s’il
   reste à combler l’écart entre apprentissage théorique et expertise
   pratique, la notion de métier pourrait presque devenir obsolète,
   glissant vers une forme de “location de cerveau“, où chacun assurerait
   à la demande et temporairement des tâches quelconques.

     Aujourd’hui je suis infographiste, demain assistant-dentaire,
     après-demain plombier ?

   Départie d’une ancienne hiérarchie sociale entre “ceux qui savent“ et
   les autres, la société se restructurerait selon un modèle possiblement
   plus juste, plus égalitaire. Cela n’oblitérerait pas nécessairement
   d’autres formes de clivage, comme le patrimoine ou le talent, mais
   pourrait au moins démocratiser à outrance la connaissance, voire
   banaliser l’érudition.



Tuner son cerveau, c’est déjà possible

   La prophétie paraît très lointaine aujourd’hui. Pourtant, plusieurs
   pistes semblent pointer dans cette direction.

   Même pour le grand public, la possibilité d’agir sur le cerveau –
   autrement qu'avec des médicaments et psychotropes – est de plus en plus
   ouverte aujourd’hui.

   Des gadgets électroniques abordables, apparus au milieu des années
   2010, proposent de mieux connaître son cerveau et, parfois, d’agir sur
   son fonctionnement : Emotiv (des électroencéphalogrammes comme à
   l’hôpital), Melomind (un casque relaxant qui crée “un univers sonore
   personnalisé réagissant à l’activité cérébrale”) ou Halo Sport (pour
   stimuler électriquement certaines partie du crâne et “optimiser les
   connexions entre cerveau et muscles”) montrent la démocratisation du
   “tuning cérébral“ – du moins dans son intention : ces équipements n’
   ayant encore prouvé scientifiquement leur efficacité.

   Dans le milieu underground du body hacking, on tente carrément
   d’améliorer son cerveau (mémoire, réactivité cérébrale, faculté
   d’apprentissage) avec des appareils de “stimulation transcrânienne à
   courant direct” (tDCS), d’usage beaucoup plus délicat (Foc.us, Apex ou
   autres). Une batterie (le plus souvent de 9 à 24 V) et des électrodes
   envoient dans le cerveau de faibles décharges électriques, avec des
   effets incertains selon les zones “électrisées”.

   La communauté scientifique s’inquiète de cet engouement pour
   l’auto-stimulation à domicile. Pour autant, cette dernière fait l’objet
   d’un vif regain d’intérêt scientifique : sur les 3 168 articles
   disponibles sur le sujet sur PubMed, 2 000 ont été publiés depuis 2015.
   Leurs résultats sont parfois contradictoires, mais la technique (et ses
   dérivées) est jugée très prometteuse pour le traitement des maladies
   neurologiques et de la douleur, ou pour la rééducation.

   Et c’est aussi une piste convaincante pour favoriser l’apprentissage et
   l’entraînement. “Bien qu’une meilleure compréhension des effets induits
   par la tDCS soit nécessaire, son impact sur l’apprentissage moteur et
   son utilisation pour explorer les substrats neuronaux impliqués dans
   l’apprentissage moteur, ont été démontrés avec succès”, conclut une
   méta-étude (analyse des études parues sur le sujet) internationale,
   publiée en décembre 2016. Giulio Ruffini le confirme :

     Les techniques de stimulation électrique transcrânienne peuvent
     jouer un rôle important pour accélérer l’apprentissage.

   Tout comme Halo, qui concluait en mai 2016 avec l’association nationale
   de ski américaine (USSA) que des athlètes professionnels pratiquant des
   exercices de saut, soumis à la tDCS durant deux semaines, “accroissent
   la puissance de leurs sauts de 70% et la coordination de leurs
   mouvements de 80%“.

   Plus troublant, HRL, filiale de Boeing et General Motors, montrait en
   2016 qu’en mesurant l’activité cérébrale de pilotes d’avions
   professionnels puis en stimulant par tDCS le cerveau de pilotes novices
   avec ces mêmes schémas, leurs capacités de pilotage étaient améliorées.
   “Il est probable que ces technologies se généralisent dans les salles
   de classe, pour l’entraînement à la conduite, la préparation d’examens
   ou l’apprentissage d’une langue”, estimait l’entreprise. En janvier
   2017, elle présentait aussi des travaux “prometteurs” pour “consolider
   des souvenirs spécifiques ou des savoirs-faire”, en appliquant la tDCS
   durant l’apprentissage, puis durant le sommeil.

Chirurgie de la mémoire

   La possibilité d’agir directement sur le cerveau (et sur les fonctions
   cognitives) est donc une réalité, et bien d’autres voies sont
   explorées.

   En 2013 aux États-Unis, deux études montraient la possibilité de
   manipuler les souvenirs chez les souris et les rats. Dans les deux cas,
   les animaux réagissaient à des sons ou à des lieux comme s’ils les
   avaient entendu ou visité auparavant, adaptant leur comportement à des
   “faux souvenirs”, artificiellement introduits dans leur cerveau.

   Pour le MIT, il faut entrer dans l’ère des neurones-engrammes, une
   théorie jusqu’alors empirique et controversée, selon laquelle la
   mémoire est – physiquement – stockée dans des groupes de neurones
   particuliers. L’existence et la compréhension des cellules engrammes,
   qui s’activent durant l’apprentissage, pourrait tout changer : si les
   souvenirs sont assimilables à des quantités biologiques, on peut les
   altérer, les remplacer ou les enrichir.

   Pour autant, il convient d’être prudent. Les techniques mises en œuvre
   pour introduire des souvenirs (chez l’animal) sont lourdes, et rien
   n’indique à ce stade que l’on pourrait manipuler la mémoire au point
   d’y introduire artificiellement des séquences sensorielles et motrices
   ultra-complexes. “Malgré des avancées notables, nous sommes toujours à
   un niveau de complexité dérisoire par rapport à la complexité du
   cerveau. Nous n’avons encore qu’une vision extrêmement réduite de son
   fonctionnement, en particulier de la mémoire”, rappelle David Guiraud,
   responsable du Projet DEMAR (INRIA Sophia - LIRMM), spécialiste des
   neuro-prothèses et de la stimulation électrique fonctionnelle.

   Les avancées en matière d’interfaces cerveau-ordinateur (BCI), bien
   qu’encourageantes, ne doivent pas tromper quant à l’ampleur du chemin à
   parcourir. “Ce qu'on sait faire aujourd'hui, c'est ‘bluffer’ le système
   cérébral en modifiant ce qu'il perçoit”, résume David Guiraud. Par
   exemple, chez un amputé, “on est capable d'évoquer des sensations (que
   la personne ressent comme réelles) d'une main et de doigts qui
   n'existent plus”. Il poursuit :

     On pourrait imaginer injecter un jour des informations qui
     n'existent pas, comme en réalité virtuelle, directement dans le
     cerveau.

   Mais cela demeurerait très éloigné d’une forme d’apprentissage
   automatique : “Aller chercher dans le cerveau d'un musicien ou d’un
   sportif pour savoir où est stocké son savoir-faire, et injecter ce
   savoir-faire sur quelqu’un d’autre relève encore de la pure
   science-fiction”.

   Cela n’empêche pas certains d’avoir des velléités en la matière. Avec
   Neuralink, Elon Musk compte développer des interfaces cerveau-machine
   d’un genre nouveau, capables « de fournir à des milliards d’individus
   des extensions d’intelligence artificielle ». Et pour Kernel, dans
   laquelle Bryan Johnson a investi 100 millions de dollars pour créer des
   puces électroniques connectables au cerveau.

     L'intelligence avancée de demain résultera d’une collaboration entre
     le naturel et l’artificiel.

   Au moins la science-fiction ne semble-t-elle pas effrayer les
   entrepreneurs-millionnaires.


   Une co-publication Inria - Usbek & Rica

   Crédibilité ? - Les gourous y croient

   Mesuré. Ray Kurzweil (Google) : “En 2029, l’apprentissage humain est
   principalement assuré par des enseignants virtuels et enrichi par des
   implants neuronaux largement disponibles. Les implants améliorent la
   mémoire et la perception, mais il n’est pas encore possible de
   directement télécharger les connaissances.” (1999,  The Age of
   Spiritual Machines)

   Plausible. Ian Pearson (Futurizon) : En 2030, un bandeau de tête sera
   capable de générer des champs de forte intensité dans la plupart des
   zones du cerveau, offrant les moyens de stimuler, de générer des
   émotions, d’accentuer ou d’atténuer, de contrôler les muscles, de
   rappeler des souvenirs et beaucoup d’autres choses.” (2016)

   Optimiste. Nicholas Negroponte (MIT) : “Dans 30 ans, nous allons
   ingérer l'information. Vous avalerez une pilule, et vous saurez
   l'anglais. Vous avalerez une pilule, et vous connaîtrez Shakespeare. Ça
   passera par le système sanguin, puis dans le cerveau, pour déposer les
   connaissances au bon endroit.” (2014)

   Enthousiaste. Michio Kaku : “Dans les prochaines décennies, nous
   pourrons télécharger des souvenirs dans le cerveau, créer un Brain-Net
   (souvenirs et émotions envoyés via Internet), enregistrer nos pensées
   et nos rêves. Avec le téléchargement de mémoire, les chômeurs pourront
   acquérir de nouvelles qualifications. Les étudiants pourront suivre des
   cours pendant leur sommeil”. (2013)


   Crédits et légendes photos : CCO Public Domain, Pixabay
   Mots-clé :
   #le saviez-vous
   / #éducation
   / #informatique
   Cyril Fiévet - Usbek & Rica

Plus d’informations sur le sujet ?

   Alan Turing et la naissance de la cryptographie moderne

Alan Turing et la naissance de la...

   Keyboard 3.0

Transparence des interfaces homme-...

   Drone

Les drones à l'assaut des nuages

Les derniers articles

Tout comprendre sur la blockchain

   Tout savoir sur la blockchain
   Lire

Des campagnes toujours plus connectées

   Des campagnes de plus en plus connectées
   Lire

Thématiques

   agriculture
   communication
   culture & loisirs
   économie & commerce
   éducation
   environnement
   habitat & urbanisme
   industries
   informatique
   santé
   transport
   vie citoyenne

Contenus

     * Articles
     * Dossiers
     * Proposer un sujet

Ils en parlent...

La Fonderie

   La Fonderie, agence numérique d’Île-de-France.

Futurapolis [Le Point]

   Futurapolis rend compte des innovations dans les grands domaines de la
   vie quotidienne.

Suivez-nous sur :

     * Facebook
     * Twitter
     * Pinterest
     * YouTube
     * Flux RSS

Propulsé par

   Inriality est propulsé par l'institut de recherche en sciences du
   numérique, Inria.

Liens utiles

     * Qui sommes-nous
     * Plan du site
     * Contact
     * Glossaire
     * Crédits et mentions légales
     * Espace presse
   Aller au contenu principal

   Sites Inria
     * Institut
     * Sujets de société
     * Culture scientifique
     * Alumni

   Inriality logo

Inriality

Partager toutes
les réalités du numérique avec Inria

Formulaire de recherche

   Recherche _______________
   Recherche

Thématiques

     * #agriculture
     * #communication
     * #culture & loisirs
     * #économie & commerce
     * #éducation
     * #environnement
     * #habitat & urbanisme
     * #industries
     * #informatique
     * #santé
     * #transport
     * #vie citoyenne

Menu mobile

     * #Thématiques

     * Articles
     * Dossiers
     * Proposer un sujet

   #agriculture
   #communication
   #culture & loisirs
   #économie & commerce
   #éducation
   #environnement
   #habitat & urbanisme
   #industries
   #informatique
   #santé
   #transport
   #vie citoyenne

Formulaire de recherche

   Recherche _______________
   Recherche
   Le 06.02.2017
   Par :
   Cyril Fiévet - Usbek & Rica

Pourquoi il faut enseigner le code informatique à l’école

   [Copublication] Dans plusieurs pays industrialisés, enseigner
   l’informatique, mais surtout apprendre à coder, sont devenus des
   priorités nationales. Comment le faire et pourquoi ?
    Partager Tweet Partager Envoyer

Barack, dessine-moi un carré

   Aux États-Unis, on ne badine pas (ou plus) avec l’importance du code. «
   Obama est le premier président à écrire un programme informatique »,
   gloussait Wired en 2014, montrant le président entouré de jeunes
   élèves, et écrivant lui-même un programme « qui dessine un carré à
   l’écran ». Démago ? Peut-être. Anecdotique ? Pas tant que ça.
   Car le président a été entendu. L’importance de l’éducation
   informatique à l’école primaire et secondaire (regroupées sous
   l'appellation "K-12", élèves de 4 à 19 ans) est reconnue par la loi
   depuis 2015. Apprendre à coder fait désormais partie du paysage (et des
   programmes scolaires), tout en étant soutenu par de vastes initiatives
   nationales, comme Code.org, une association lancée en 2013, avec des
   résultats impressionnants. En septembre 2016, elle annonçait avoir
   formé 43 700 enseignants qui pourront diffuser l’apprentissage du code
   à plus d’un million d’élèves, y compris dans 2000 écoles jusqu’alors
   dépourvues de tout enseignement informatique. Et l’association promeut
   aussi son "Heure de code", des événements offrant aux citoyens de tous
   âges de découvrir brièvement la programmation informatique. Plus de dix
   millions de personnes s’y sont essayé, avec quelques 283 327 596 heures
   de codes dispensées – soit plus de 32 000 années dévolues à
   l’apprentissage de l’informatique.

   D’autres pays ne sont pas en reste. En Estonie, le programme Proge
   Tiiger a lancé dès 2012 l’apprentissage du code (dans une vingtaine
   d’écoles pilotes), pour les enfants à partir de sept ans. Au Canada,
   l’opération "Canada learning code", démarrée en octobre 2016, a pour
   ambition « d’enseigner à coder à dix millions de Canadiens d’ici à 2027
   ». Elle a déjà formé plus de 50 000 personnes et propose de multiples
   modules, adaptés à tous les âges.
   La Grande-Bretagne est aussi pionnière en la matière. Depuis septembre
   2014, l’apprentissage de la programmation informatique y est inclus
   dans les programmes des écoles primaires. Et en mars 2016, une vaste
   (et innovante) initiative montée par la BBC enfonçait le clou : la
   distribution gratuite, dans les écoles, d’un million d’ordinateurs
   miniatures (“micro:bit”, une version simplifiée à l'extrême d'un PC, au
   format carte de crédit, similaire au Raspberry Pi) conçus
   spécifiquement pour apprendre à programmer.



Monsieur le Président...

   En France, la prise de conscience de l’importance du sujet semble avoir
   culminé en avril 2014, avec la remise d’une lettre ouverte au Président
   de la République, François Hollande, cosignée par une longue liste de
   sommités scientifiques (et d’anciens Premiers ministres, Lionel Jospin
   et Michel Rocard). La lettre se voulait claire : un « développement
   massif de l’enseignement de l’informatique » est nécessaire en France.
   Si les signataires saluaient l’introduction de l’informatique en
   Terminale S depuis 2012, ils jugeaient l’effort « insuffisant pour
   placer notre pays dans le peloton de tête des nations qui décideront de
   l’innovation » et proposaient notamment « de faire entrer
   l’informatique en tant que discipline à part entière dans le système
   éducatif français, avec des initiations à l’école primaire et une
   entrée dès le collège. »
   Deux ans plus tard, en août 2016, un document de synthèse de la Société
   informatique de France (SIF) insistait toujours, en expliquant comment
   l’on pourrait « enseigner l’informatique de la maternelle à la
   terminale » et détaillant les « piliers de l’informatique » –
   algorithme, machine, langage, information – « que tous les élèves
   doivent s’approprier et ce quel que soit leur parcours dans l’éducation
   nationale. »
   Les choses bougent pourtant et, en vertu d’une refonte des programmes
   scolaires pour la rentrée 2016, l'enseignement de l'informatique en
   France concerne désormais aussi les élèves du primaire et du collège.
   Si les spécialistes saluent l’orientation prise par l’Education
   Nationale, beaucoup estiment qu’il faut aller plus loin. Florent
   Masseglia, chercheur Inria de l’équipe Zenith, impliqué dans plusieurs
   projets de vulgarisation scientifique et de formation des enfants
   (notamment Les petits débrouillards - Occitanie), juge :

     Il reste deux goulots d'étranglement, sur lesquels il faut
     absolument progresser : le temps alloué en classe à ces
     enseignements et la formation des enseignants.

   « Le temps alloué est encore trop faible, avec une installation
   balbutiante (en option de terminale pour l'ISN, et au stade de
   démarrage pour le primaire et le collège) », estime-t-il, concluant que
   « pour être à la hauteur de l'enjeu, il s'agit de voir les choses en
   grand et pas de seulement bricoler quelques adaptations dans un coin
   (par exemple avec le CAPES). »
   De fait, les initiatives se sont multipliées ces dernières années. Dans
   la cadre de sa mission de médiation scientifique, Inria aide les
   enseignants à apprendre l’informatique à leurs élèves : vidéos, cours
   en lignes (MOOC), ou activités "clé en main, pour le primaire et le
   secondaire, y compris dans le cadre de Pixees, qui centralise des
   ressources pour comprendre le numérique. Point d’orgue de la démarche,
   Class’Code, qui fait partie des quatre programmes d'investissement
   d'avenir "Décodez le code", propose « un programme de formation gratuit
   à destination de toutes personnes désireuses d’initier les jeunes de 8
   à 14 ans à la pensée informatique. » Plusieurs associations ou
   fondations, comme La main à la pâte, Epi ou d’autres, apportent leur
   pierre à l’édifice, avec par exemple la diffusion gratuite du guide "1,
   2, 3… codez !" à 10 000 enseignants en septembre 2016.

Coder n’est pas jouer

   Reste à savoir ce que l’on enseigne. Pour beaucoup, l’heure n’est plus
   à apprendre à utiliser l’informatique mais plutôt à parler son langage.
   Ce qui fait dire à Léon Sterling, professeur émérite et ancien doyen de
   l’université de Swinburne, en Australie, qu’il faut « apprendre aux
   enfants à coder » mais que, pourtant, il faut limiter « l’usage
   obligatoire des laptops dans les salles d’écoles. » Roberto Di Cosmo,
   directeur de recherche Inria, professeur d'informatique à Paris VII et
   membre de l’Institut de recherche en informatique fondamentale (ex
   PPS), renchérit :

     On peut passer des heures à cliquer sur une souris sans rien
     apprendre d'informatique, on peut aussi apprendre beaucoup
     d'informatique sans toucher une souris.

   Martin Vetterli, qui présidera l’Ecole polytechnique fédérale de
   Lausanne l’an prochain, avance que l’informatique pourrait être « le
   latin du 21e siècle » et que, à l’instar des langues anciennes aidant à
   comprendre et maîtriser les langues européennes, savoir programmer
   aidera à comprendre le monde et son fonctionnement. Cette notion fait
   son chemin, comme le suggère l’initiative nationale américaine "Code as
   a Second Language" – le code comme deuxième langue. En viendrons-nous à
   pleinement assumer ce qui est bel et bien un nouveau langage : « J’ai
   pris Anglais première langue et Javascript/PHP/C++ seconde langue » ?
   Pas si dénué de sens, au point que certains, quitte à s’attirer les
   foudres des défenseurs d’une école "déconnectée" (des réalités ?),
   suggèrent que l’apprentissage du code pourrait même précéder celui de
   la lecture : « L’initiation à la programmation peut commencer dès le
   plus jeune âge, par exemple à la maternelle, en utilisant des langages
   graphiques, qui ne demandent pas de connaître les lettres de l’alphabet
   », souligne la SIF.
   Pour autant, la comparaison avec l’enseignement des langues a ses
   limites car un langage de programmation se caractérise par « un
   vocabulaire limité et une grammaire assez rigide. On est donc bien loin
   de l'apprentissage des langues où l'on recherche des nuances de
   langages », souligne Marie Duflot-Kremer, maître de conférences en
   informatique à l'université de Lorraine (Loria) et très active en
   matière de médiation scientifique.

Du langage à la science, de la science à la pensée

   Parler l’informatique n’est donc pas la seule finalité, d’autant que
   l’informatique doit se fondre avec les autres disciplines. «
   L’informatique est une science, à part entière », rappelle Florent
   Masseglia, mais « l’interdisciplinarité est dans l'ADN de
   l'enseignement de l'informatique –l’informatique et les autres
   disciplines doivent s'alimenter mutuellement. »

     Aborder l'informatique comme une science et pas seulement comme une
     technique permet de découvrir les concepts qui ont fait de
     l'informatique ce qu'elle est.

   « Dès le plus jeune âge on peut s'ouvrir à des notions comme le
   parallélisme, les bases de données ou le codage des informations, et
   tout cela de manière ludique, avec ou sans ordinateur », confirme Marie
   Duflot-Kremer, qui est d’ailleurs l’auteure scientifique d’une série de
   vidéos réalisées par Pixees, exposant des façons ludiques d’apprendre
   l’informatique aux plus jeunes.
   PC 1512 Au fond, apprendre l’informatique va bien au-delà de
   l’informatique, comme le soutient Colin de la Higuera, professeur à
   l'université de Nantes, chercheur au laboratoire d'informatique de
   Nantes-Atlantique (Lina) et ancien président de la SIF. Pour lui, « La
   démarche procédurale, l’abstraction, la capacité de créer des
   algorithmes sont autant de qualités à apprendre puis à maîtriser pour
   résoudre des problèmes de toutes natures. [Le code nous permet
   d’exécuter cette résolution. L’informatique nous permet de la
   comprendre. [...] C’est cette matière qu’il convient d’enseigner. »
   L’essentiel est donc que l’apprentissage du code, à l’instar de celui
   de la parole, façonne et structure la pensée. « Comprendre comment
   exprimer les concepts pour permettre à un ordinateur d’effectuer des
   tâches précisément et efficacement est bien plus important que le
   langage de programmation utilisé », explique Sterling, concluant
   combien la « pensée algorithmique », ou « pensée informatique »,
   amenant à raisonner de façon abstraite sur la façon de traiter des
   tâches, est d’un intérêt primordial.
   « Pour coder, les élèves réaliseront l'intérêt d'apprendre à "gérer un
   projet" et donc clarifier ce qu'ils veulent créer, décomposer leur
   démarche en différentes étapes ou encore savoir présenter leur œuvre de
   la description du projet, jusqu'au résultat », explique Masseglia,
   concluant que l’apprentissage de l’informatique « stimule le
   raisonnement, peut aider à mieux comprendre d'autres disciplines et
   aussi recapter l'attention d'élèves en difficulté et qui vont se
   prendre au jeu. »


   Une co-publication Inria - Usbek & Rica


   Crédits et légendes photos : Wikimedia Commons ; Commitstrip ; CC0
   Public Domain / Public domain pictures.net ; CC0 Public Domain / Old
   Computers
   Mots-clé :
   #le saviez-vous
   / #éducation
   / #informatique
   Cyril Fiévet - Usbek & Rica

Plus d’informations sur le sujet ?

   Alan Turing et la naissance de la cryptographie moderne

Alan Turing et la naissance de la...

   Keyboard 3.0

Transparence des interfaces homme-...

   Drone

Les drones à l'assaut des nuages

Les derniers articles

Tout comprendre sur la blockchain

   Tout savoir sur la blockchain
   Lire

Des campagnes toujours plus connectées

   Des campagnes de plus en plus connectées
   Lire

Thématiques

   agriculture
   communication
   culture & loisirs
   économie & commerce
   éducation
   environnement
   habitat & urbanisme
   industries
   informatique
   santé
   transport
   vie citoyenne

Contenus

     * Articles
     * Dossiers
     * Proposer un sujet

Ils en parlent...

La Fonderie

   La Fonderie, agence numérique d’Île-de-France.

Futurapolis [Le Point]

   Futurapolis rend compte des innovations dans les grands domaines de la
   vie quotidienne.

Suivez-nous sur :

     * Facebook
     * Twitter
     * Pinterest
     * YouTube
     * Flux RSS

Propulsé par

   Inriality est propulsé par l'institut de recherche en sciences du
   numérique, Inria.

Liens utiles

     * Qui sommes-nous
     * Plan du site
     * Contact
     * Glossaire
     * Crédits et mentions légales
     * Espace presse
