   Neustadt.fr
     * 02 nov. '17 — essay Against an Increasingly User-Hostile Web
     * 30 sept. '16 — tutorial A Beginner's Guide to Crafting a Blog with
       Metalsmith
     * 07 mars '16 — guide Teaching Myself German
     * 06 janv. '16 — essay 32c3 - Chaos Communication Congress
     * 02 nov. '15 — essay Physics in Metal

   —

   Parimal Satyal is a Paris-based designer/geek who enjoys cosmology,
   dark beer, the open internet, metal music and foreign languages. More–

   Neustadt.fr is his collection of essays, reviews and music.
   ← Neustadt.fr

Against an Increasingly User-Hostile Web

   02 novembre 2017 — Parimal Satyal

   We're quietly replacing an open web that connects and empowers with one
   that restricts and commoditizes people. We need to stop it.

   I quit Facebook seven months ago.

   Despite its undeniable value, I think Facebook is at odds with the open
   web that I love and defend. This essay is my attempt to explain not
   only why I quit Facebook but why I believe we're slowly replacing a web
   that empowers with one that restricts and commoditizes people. And why
   we should, at the very least, stop and think about the consequences of
   that shift.

The Web: Backstory

   (If you want, you can skip the backstory and jump directly to the table
   of contents).

   I love the web.

   I don't mean that in the way that someone might say that they love
   pizza. For many of us in the early 2000s, the web was magical. You
   connected a phone line to your computer, let it make a funny noise and
   suddenly you had access to a seemingly-unending repository of thoughts
   and ideas from people around the world.

   It might not seem like much now, but what that noise represented was
   the stuff of science fiction at the time: near-instantaneous
   communication at a planetary scale. It was a big deal.

   I was an average student at school. Despite well-meaning and often
   wonderful teachers, I didn't thrive much in a school system that valued
   test performance and fact-retention over genuine curiosity. Had it not
   been for the web, I might have convinced myself that I was a poor
   learner; instead, I realized that learning is one of my great passions
   in life.
   One of my earlier websites, from 2001 What remains of my fan site for
   German powermetal band Gamma Ray from 2001, archived thanks to the
   wonderful folks over at Archive.org

   I was 11 when I set up my first website. Growing up in Nepal, this was
   magical. Almost everything I love today — design, aviation, cosmology,
   metal music, computation, foreign languages, philosophy — I discovered
   through the many pages that found their way to my web browser. All I
   needed were curiosity, a phone line and that strange little electrical
   song. And good old Netscape Navigator.
   Netscape Navigator 4.04 Netscape Navigator 4.04, source: A Visual
   Browser History, from Netscape 4 to Mozilla Firefox

   The web enabled that. It's one of humanity's greatest inventions. And
   now, we the architects of the modern web — web designers, UX designers,
   developers, creative directors, social media managers, data scientists,
   product managers, start-up people, strategists — are destroying it.

   We're very good at talking about immersive experiences, personalized
   content, growth hacking, responsive strategy, user centered design,
   social media activation, retargeting, CMS and user experience. But
   behind all this jargon lurks the uncomfortable idea that we might be
   accomplices in the destruction of a platform that was meant to empower
   and bring people together; the possibility that we are instead building
   a machine that surveils, subverts, manipulates, overwhelms and exploits
   people.

   It all comes down a simple but very dangerous shift: the major websites
   of today's web are not built for the visitor, but as means of using
   her. Our visitor has become a data point, a customer profile, a
   potential lead -- a proverbial fly in the spider's web. In the guise of
   user-centered design, we're building an increasingly user-hostile web.

   If you work in the design/communication industry, consider this essay
   introspective soul-searching by one of your own. If you're a regular
   web user, consider this an appeal to demand a better web, one that
   respects you instead of abusing and exploiting you.

   Note: The entire essay is rather long so feel free to skip to
   individual parts:
    1. The Web was Born Open: a very brief history of the web
    2. The Modern Web (of Deception): the disturbing state of the web
       today
    3. Track the Trackers, an Experiment: with whom websites are sharing
       your information
    4. Gated Communities: recentralization and closed platforms
    5. The Way Forward: open tools, technologies and services for a better
       web

The Web was Born Open

   It all began in the early 90s.

   The Internet — the physical network that allowed computers around the
   world to communicate — was already in place but it remained
   inaccessible to most people. You had to know how to use a local client
   to connect to a remote FTP, Usenet, Gopher or an email server. This was
   before the days of ubiquitous graphical user interfaces so you had to
   type funny commands into a terminal, one of those black screens with
   green text that that hackers supposedly use to do Bad Things.
   Usenet Archives from 1981 on gopher server Quux.org Usenet Archives
   from 1981 on gopher server Quux.org, accessed 31 October 2017 via lynx

   Meanwhile, Tim Berners-Lee was working as an independent contractor at
   CERN in Geneva. Frustrated with how difficult it was to find, organize
   and update technical documentation, he proposed a solution that
   involved "global computer networked information system" that "presented
   users with a web of interlinked documents", called Mesh. Pretty soon it
   became apparent that WWW — World Wide Web, as it came to be known —
   could do more than just link technical documents.
   Usenet Archives from 1981 on gopher server Quux.org The world's first
   website, accessed 31 October 2017 via lynx

   On April 30 1993, CERN made a bold decision. It decided to release WWW
   into the public domain. It renounced all intellectual property rights
   and essentially invited anyone at all, anywhere in the world, to play
   with it. Later, the director of CERN who approved the decision said
   that he was inspired by Richard Stallman's vision of free, open
   software.

   Had CERN decided otherwise and patented the technology to then license
   it for money, the web would arguably not have taken off the way it did.
   It might have died out like the Minitel did in France. The web as we
   know it was born of a vision to create an open system that brought
   people and ideas together, with documents that "may reside on any
   computer supported by that web".

   Advances in the hyper-text transfer protocol (HTTP), network
   infrastructure, web browsers and standards, consumer Internet access,
   accessible hosting and blogging platforms led to a massive
   democratization and adoption of the web.

   Soon, anyone could put a document on the web and any document could
   link to any other. It created a completely open platform where a writer
   in Nepal could freely share her ideas with a dancer in Denmark. A
   climate science student in Nairobi could access data from the McMurdo
   weather station in Antarctica. You could start reading about logical
   fallacies and end up on a website about optical illusions. Read about
   the history of time-keeping and end up learning about Einstein's
   special theory of relativity. All interests were catered to.
   Information could truly be free: transverse borders, cultures and
   politics.

   That is the web at its best.

   My own journey from designing that first website as an 11-year old
   "webmaster" in Nepal to writing this article as a UX Consultant in
   France has its origin in that 1993 decision by CERN.

The Modern Web (of Deception)

   The modern web is different.

   It's naturally different from a technological standpoint: we have
   faster connections, better browser standards, tighter security and new
   media formats. But it is also different in the values it espouses.
   Today, we are so far from that initial vision of linking documents to
   share knowledge that it's hard to simply browse the web for information
   without constantly being asked to buy something, like something, follow
   someone, share the page on Facebook or sign up to some newsletter. All
   the while being tracked and profiled.

   Almost every website you go to today reports your activities to third
   parties that you most likely neither know nor trust. They record where
   you come from, what pages you visit, how long you stay on each, where
   you click and where you go next. In fact, since so many websites report
   to the same third parties, these companies can essentially have your
   web history on file as you go from link-to-link, website to website.
   Like an omnipotent eye embedded on Sir Berners-Lee's global system of
   interlinked documents, noting down everything you do and reporting to
   private entities who then sell this information for profit.

   These companies build profiles, anonymous at first, with your interests
   and navigational behavior. These profiles can then get increasingly
   personal: they might include your email addresses, home address,
   income, educational history, political affiliation, information on your
   family. Over time, they can cross-reference all this information with
   your location data to figure out where you work, which restaurants you
   go to, where your gym is. Recently, we even learned that Google was
   able to associate your offline purchases with your online ad viewing
   history (albeit anonymously, it would appear). Once they have that,
   they can look into your behavior and psychology: what kind of ads do
   you tend to click on? What kind of messages resonate most with you?
   What are the best strategies to influence your opinion?
   Screenshot of Mr. Alexander Nix presenting the work of Cambridge
   Analytica, video The Power of Big Data and Psychographics on Youtube
   Screenshot of Mr. Alexander Nix presenting the work of Cambridge
   Analytica, video The Power of Big Data and Psychographics on Youtube

   The Leave campaign responsible for Brexit in the United Kingdom and
   Donald Trump's 2016 presidential campaign both bought the services of a
   certain Cambridge Analytica, a company that boasts a gigantic database
   containing personal details amounting to "close to four or five
   thousand data points on every adult in the United States" (their own
   words). The goal? Craft hyper-personalized messages to change voting
   behavior based on your individual personalities, and by extension, your
   attitudes, opinions and fears. So if you are identified as a dad of
   three young kids in rural Texas, the message is nuanced to suggest that
   only a certain candidate will be able to protect your family against
   real or imagined threats. If you are identified as a patriot who's
   previously posted comments about gun rights and the second amendment,
   it might be about crime rates and how the opposition is trying to take
   your constitutional rights away from you.

     You become a manipulable data point at the mercy of big corporations
     who sell their ability to manipulate you based on the data you
     volunteer.

   This is the equivalent of someone following you in real life as you go
   about your everyday business, like a private eye who notes down with
   whom you meet, what you talk about, what you spend time looking at in
   stores. A private eye who takes notes and then sells it to the highest
   bidder. But you got to enter the store for free, so you should be so
   glad. The stores might also justify it. "Sure it's a bit invasive, but
   we'll be able to give you better recommendations if we know what you
   like".

   But how do they get all this personal information -- where you live,
   who your friends are, what your religion and ethnicity are, where you
   were last night, what you bought on Monday? Most of it you volunteer
   yourself on social platforms like Facebook, Twitter and Instagram. The
   little share buttons you see on websites aren't just there to make it
   easy for you to post a link to Facebook; they also allow Facebook to be
   present and gather information about you from pretty much any website.

   But how can you know that any of this is true?

Track the Trackers: An Experiment

   Perhaps you think I'm being a tad too dramatic.

   In your defense, all of this does sound like some dystopian fantasy.
   But I'm not that great a fiction writer quite yet. Let me illustrate my
   point with a little experiment. We'll pick a major website that you
   might visit regularly and identify third parties it shares your
   information with.

   We'll need a few things:
     * a test website
     * Webbkoll, a web privacy check tool by Dataskydd.net, a Swedish
       association for data protection and privacy (of which I'm a proud
       member) and
     * A web inspector

   Let's take an article that was published around the time I first
   started working on this article (which is last year; I'm a slow
   writer): Astronomie : la sonde Juno s’est mise en orbite autour de
   Jupiter (Astronomy: space probe Juno put in orbit around Jupiter).
   Le Monde article 'Astronomie : la sonde Juno s’est mise en orbite
   autour de Jupiter' Le Monde article Astronomie : la sonde Juno s’est
   mise en orbite autour de Jupiter

   If you run this URL through Dataskydd's Webbkoll and a web inspector
   tool (I used Chromium's web inspector), you learn a few interesting
   things: the page is 3.1 MB in size, makes about 460 HTTP requests of
   which 430 are third-party requests (outside of its parent domain) and
   takes 20 seconds to fully load on a fast 3G connection (from Paris,
   France).

   It also stores 100 cookies (these are little pieces of text stored on
   your computer by websites other than lemonde.fr; cookies are normally
   used to save session information but can also be used to identify and
   track you) and contacts 118 third-parties. And if all this weren't
   enough, your connection to LeMonde and the majority of third-party
   connections are over unsecure HTTP protocol (instead of the more secure
   HTTPS, which should be a basic requirement).

   That's a lot of big numbers for an article of 1500 words, three images
   and one video.

   Now let's look at some of the third parties that the page connects to
   when you load it:
     * Weborama: advertising platform for analytics, digital marketing and
       behavioral targeting
     * Visual Revenue: predictive analytics platform
     * AppNexus: multimedia content monetization service
     * Outbrain: "online advertiser specializing in presenting sponsored
       website links" (Wikipedia)
     * Facebook: a social network and micro-targeted advertising platform
     * Cedexis: a multi-CDN application delivery platform

   Note: In an earlier version of the article, I had mistakenly identified
   Cedexis as an "ad-delivery platform", which it is not. My apologies to
   Cedexis for the error.

   Some of these are simply tools to manage content delivery but many are
   advertising or content monetization platforms. Companies like Weborama
   make money by selling information about you. When people say, "you're
   the product," it isn't just some analogy, it accurately reflects the
   business propositions of many such companies.

   What's surprising is that the bulk of the information transferred
   between LeMonde and you doesn't even concern the actual article. If you
   were to isolate the actual content—the words, images and video—and put
   it in an HTML file, it would weigh considerably less than 3.1 MB and
   would make a lot fewer requests.

   If fact, I did just that and made three versions :
     * Version A: With the original text (including comments, images and
       video)
     * Version B: With the original text (including comments, images) but
       no video
     * Version C: With just the original text (including comments), no
       images or video

   Some numbers:
   Original (LeMonde.fr) Version A Version B Version C
   Page Size 3,1 MB 1 MB (32%) 183 KB (5,8%) 17 KB (0,54%)
   Load Time 20,9 s 4,6 s (19,4%) 2,8 s (9,6%) 662 ms (3,2%)
   Requests (total) 459 108 (23,5%) 5 (1%) 1 (0,2%)
   Requests (third-party) 436 64 (14,7%) 4 (0,9%) 0
   Third Parties Contacted 118 17 (14,4%) 2 (11,8%) 0
   Cookies (total) 100 16 (16%) 0 0
   Cookies (third-party) 73 16 (21,9%) 0 0
   Text
   (% of Page Size) 0,5 % 1,7 % 9,5 % 100 %
   Text + Images
   (% of Page Size) 5,8 % 17,9 % 100 %
   Text + Images + Video
   (% of Page Size) 32,3 % 100 %

   Note: Data on the number of requests (first- and third-party) and
   cookies (first- and third-party) comes from Dataskydd Webbkoll. The
   rest of the data comes from Chromium's built-in web inspector. All
   connections were made from Paris, France with cacheing disabled and the
   bandwidth throttled to simulate a "fast 3G" connection. You can run
   these numbers yourself; they should vary only nominally depending on
   where you are. If you find errors, please let me know.

   Those are some very interesting figures. Some observations:
     * The actual article (text and three images, version B) makes up less
       than 6% of the total size of the page on LeMonde.fr. This means
       that 94% of the data transferred between you and LeMonde.fr has
       nothing to do with the article.
     * What about the video, you ask? Before you even play it, that one
       video adds over a 100 requests (60 of which are to 15 additional
       third parties) and 16 third-party cookies. It also adds over 800 KB
       of data. Again, this is before you even decide to play the video.
       The video might be related to the content, but it’s doing a lot
       more than that.
     * Even compared to the version with the video (Version A), the
       LeMonde article makes about 450 additional third party requests, of
       which 370 are to about 100 additional third parties, storing 100
       additional cookies (55 of which are third party cookies). It also
       adds over 2 MB to the page. All that is data that has nothing do
       with and completely unnecessary to load the article you're reading.
     * The text + image version (Version B) is able to load the entire
       text and the 3 images with only 5 requests and no cookies
       whatsoever. Adding a video should reasonably add one or two more
       requests and maybe one cookie, not 450 requests and 100 cookies,
       the majority of which on behalf of companies you neither know nor
       trust, including those who track and sell your data for profit.
     * The Le Monde page will continue to periodically transfer data and
       make additional requests even after it has completely loaded and as
       you scroll and interact with the page. If you monitor network
       traffic, a lot of this data is going to third-party tracking
       scripts. For example, a request is made to Xiti.com (a web
       analytics company) every few seconds.
     * If you don't use a content blocker, you will notice that in just a
       matter of minutes, over 30 MB of data will be transfered between
       your browser and the 100+ third parties. The number of requests
       will go into the thousands. This will continue to rise as long as
       you leave your browser open.

     Essentially, this means that about 94% of the data being transferred
     and 99% of the requests being made have nothing to do with the
     article itself. Le Monde might principally be a newspaper in its
     printed version, but the online version is an invasive, insecure
     advertising platform with good content (in that order).

   If you're curious, try using Webbkoll on other websites you visit to
   see how privacy-friendly and respectful these websites are. We'll get
   into how to protect yourself from these third-party trackers later on
   in the article.

   All this might not be illegal (although there's some doubt, especially
   now that in the context of up the upcoming European General Regulation
   on Data Protection), but it is rather disrespectful towards the user.
   Not only are these websites breaking my trust—when I visit your
   website, I entered into contact with you, not 80 other websites—but
   they are loading content from websites neither know nor trust. Some of
   which have been know to spread malware.

     Using an ad/content-blocker isn't cheating the system; it's taking
     very basic precautions that websites like Le Monde can't be bothered
     to take to protect you. For me, it's a basic necessity in the modern
     web.

   If you're reading this and are wondering what to do to protect
   yourself, skip ahead to the The Way Forward section.

   If you run a website and you put official share buttons on your
   website, use intrusive analytics platforms, serve ads through a
   third-party ad network or use pervasive cookies to share and sell data
   on your users, you're contributing to a user-hostile web. You're using
   free and open-source tools created by thousands of collaborators around
   the world, over an open web and in the spirit of sharing, to subvert
   users.

Gated Communities

   One of the most impressive things about the Internet (and consequently
   also the web) is that it is decentralized. No central authority gets to
   decide which page is more important than others and you don't have to
   play by anyone else's terms to publish and read what you want. There
   isn't anything like a main server that stores the code that runs the
   Internet; it's just a protocol on a physical backbone (of undersea
   cables).

   You could buy a Raspberry Pi Zero today for less than 10€, connect it
   to the Internet, set up a chat server on it, give it a public address
   and the world would be able to connect to it and talk to one other.
   Sure, it might not perform too well and no one might actually use it,
   but it is technically possible.

   But most of the time we spend on the web today is no longer on the open
   Internet - it's on private services like Facebook, Twitter and
   LinkedIn. While Facebook provides a valuable service, it is also a
   for-profit, company. Their source of revenue is advertising. It is the
   epitome of centralized.
   Francisco Goya's paintain The Naked Maja Francisco Goya's The Naked
   Maja (1800)

   Try posting a picture of the Francisco de Goya's "The Naked Maja" or
   your naked breasts (if you're a woman) on Facebook; it'll almost
   certainly be removed. It's against their terms of use. To use their
   platform, you have to agree to whatever conditions they set, however
   absurd. If you replace the open web with Facebook, you're giving up
   your right to publish and share on your terms. The data that you post
   there does not belong to you; you're putting it in a closed system. If
   one day Facebook decides to shut down — unlikely as that might seem
   today — your data goes with it. Sure, you might be able to download
   parts of it, but then what?
   Tumblr Blog Our Incredible Journey, a short history of start ups Tumblr
   Blog Our Incredible Journey, "cataloging the thrilling opportunities
   start-ups are offered when their incredible journey continues by being
   bought by an exciting company. However, as a user of the start-up’s
   service, your own incredible journey must end, because all of your
   photos and writing and checkins and messages and relationships must now
   be deleted".

   This works because they know you'll agree to it. You'll say you don't
   have a choice, because your friends are all there — the infamous
   "network effect". This is Facebook's currency, its source of strength
   but also a crucial dependency.

     And this is what we often fail to realize: without its users—without
     you— Facebook would be nothing. But without Facebook, you would only
     be inconvenienced. Facebook needs you more than you need it.

   And they do their best to keep you on their website as long as
   possible. Your attention is worth a lot to a lot of companies who are
   convinced that traditional advertising is dead and that micro-targeted
   campaigns work better. (And they mostly do, from their point of view).
   This drives them to come up with absurd techniques to create addiction:
   wish your friend happy birthday, wish your colleague a happy work
   anniversary (who does that?), here's a video we made about you, three
   friends are going to an event near you, continue watching the video you
   started even as you scroll, be the first to comment, react to this
   photo, tell everyone what you're to. The longer you stay, the more
   information you give, the more valuable your profile — and the platform
   — is to advertisers.

   I'm not saying that what Facebook is doing is entirely unethical. It
   has to make money to make up for the resources it employs to keep the
   website running and it does so by advertising. Every time you choose to
   use a free service like Instagram, LinkedIn, Gmail or Snapchat, you are
   paying for the convenience with your eyes, your data and your
   attention. There's nothing inherently wrong as long you as you
   understand and consent to this exchange of value. But do you? Does your
   daughter? Your dad?

   What I'm against is the centralization of services; Facebook and Google
   are virtually everywhere today. Through share buttons, free services,
   mobile applications, login gateways and analytics, they are able to be
   present on virtually every website you visit. This gives them immense
   power and control. They get to unilaterally made decisions that affect
   our collective behavior, our expectations and our well-being. You're
   either with them or out. Well, I chose out.

   You see, the web wasn't meant to be a gated community. It's actually
   pretty simple.

   A web server, a public address and an HTML file are all that you need
   to share your thoughts (or indeed, art, sound or software) with anyone
   in the world. No authority from which to seek approval, no editorial
   board, no publisher. No content policy, no dependence on a third party
   startup that might fold in three years to begin a new adventure.
   A website about Doom Level design A website on Doom level design on
   Geocities from 1999, accessed October 31, 2017 via Archive.org

   That's what the web makes possible. It's friendship over hyperlink,
   knowledge over the network, romance over HTTP.

   In fact, the browser you're reading this on (Chrome, Firefox, lynx,
   whatever), the web server that's hosting this website (Nginx), the
   operating system that this server runs on (Ubuntu), the programming
   tools used to make it all work (python, gcc, node.js...) -- all of
   these things were created collectively by contributors all around the
   world, brought together by HTTP. And given away for free in the spirit
   of sharing.

   The web is open by design and built to empower people. This is the web
   we're breaking and replacing with one that subverts, manipulates and
   creates new needs and addiction.

The Way Forward

   If you want to protect yourself (as a user) from predatory web
   marketing companies and defend the open web, there a few things you can
   do today at an individual level.

   If you're a web professional (a designer, UX consultant, strategist,
   programmer...), there are a number of considerations for better
   respecting your users and protecting their privacy (and your
   integrity).

   Here's a basic list:

For end users (you, dear reader)

     * If you use Chrome as your main browser, consider switching to the
       open-source version called Chromium. Better yet, switch to Mozilla
       Firefox, developed by the not-for-profit Mozilla Foundation that
       has a solid record of defending your privacy. Consider minimalist
       browsers like Min (and choose to block all ads, trackers and
       scripts) to browse news websites.
     * Install a content/ad blocker for your browser: I recommend uBlock
       Origin (available for Firefox, Chrome and Safari on most
       platforms). You can also complement this with the Electronic
       Frontier Foundation's Privacy Badger tool that protects you from
       invasive ads and third-party tracking.
     * Install HTTPS Everywhere for your browser; this forces your
       information through secure, encrypted channels (HTTPS vs HTTP one)
       if possible. It can also be configured to only allow connections to
       HTTPS websites.
     * Think about how much information/details you provide to social
       media platforms like Facebook, Linked, Twitter and Instagram. They
       already have quite a lot (including the ability to recognize you by
       name on photographs), but what other information are you
       volunteering? Where you are, whom you're with, information about
       your friends?
     * Consider quitting social networks, especially Facebook (but
       download your data first!). What would you miss the most? Are there
       alternatives?
     * Consider alternatives to free services provided by the likes of
       Google and Facebook. Today, if both of these companies shut down
       (or implement policies I don't like), I would mostly be fine
       because my contact with them is limited. I use DuckDuckGo and
       Startpage for search (free); FastMail for email and calendar (less
       than 40€ a year) ; HERE WeGo for maps (free); Signal, email and IRC
       for messaging (free, along with iMessage, Whatsapp and Twitter);
       Digital Ocean for web hosting (about 5€ per month).
     * Pay for services and content that you like, if you are able. If you
       like reading The Guardian, for example, consider subscribing. If
       your favourite YouTube channel is on Patreon, consider pledging a
       small amount per video. If you like services like Pinboard.in that
       charge in return for a useful service, buy it. There's mutual
       respect when both the user and the service provider know what basic
       service they are buying/selling.
     * At the very least, consider that the platforms you use need you
       more than you need them. You have power over them (unfortunately,
       in numbers) and they know it. If enough people care about privacy
       and respect for their data and time, platforms will have to adapt
       to stay relevant.

For web professionals (you, fellow industry colleague)

     * Consider not putting share buttons everywhere. They're visual noise
       and make third party connections every time the page is loaded
       (adding to load time). If you have to, create your own instead of
       using ones provided by Facebook and co. (so that a click is needed
       before a request is made to their servers)
     * Support HTTPS. It's super easy (and free!) with Let's Encrypt so
       you don't have an excuse to not respect your users' privacy
     * Think about accessibility also in terms of page size, load times
       and tech requirements: will your website work without Javascript?
       What percentage of your the total weight of your page is actual
       information? How many third party requests are you making? How long
       would it take to load on a 56.6k dial-up or on EDGE? How does it
       render for speech readers? Can it be read via a text-based browser?
       (It's a fun experiment; try visiting your website with a text-based
       browser like lynx or Links).
     * Refuse client requests to implement hyper-invasive technologies
       like canvas fingerprinting.
     * Consider replacing Google Analytics with a more privacy-respecting
       analytics software like Piwik. Even better if you can host it
       yourself!
     * Minimize third-party dependencies like Google Fonts (you can
       self-host them instead).
     * Avoid ad networks (like the plague!) if possible. Serve your own
       ads by selling ad space the old school way if you're able. If not,
       explore privacy-respecting methods of serving ads, including
       developments powered by the blockchain (like the Basic Attention
       Token).
     * Respect Do Not Track.
     * Carefully consider the benefits of hyper personalisation and
       retargeting. The benefits are debatable but the long term
       consequences might be disastrous. Ask yourself: would you be okay
       with a company collecting as much data (as you seek to collect) on
       your teenage daughter, your nephew in college, your husband or your
       grand-mother?
     * Consider business models where you actually respect your clients
       and your website visitors instead of using them. If you can't be
       honest about your business model with your client, maybe you need
       to ask questions.

Thoughts and feedback

   It all comes down to one simple question: what do we want the web to
   be?

     Do we want the web to be open, accessible, empowering and
     collaborative? Free, in the spirit of CERN’s decision in 1993 or the
     open source tools it's built on? Or do we want it to be just another
     means of endless consumption, where people become eyeballs, targets
     and profiles? Where companies use your data to control your
     behaviour and which enables a surveillance society — what do we
     want?

   For me, the choice is clear. And it's something worth fighting for.

   I hope this article has been interesting. If you have thoughts—you
   agree, disagree, have reservations, other ideas or a suggestion—I'd
   love to hear them! This article is on GitHub; if you'd like you can
   send a pull request with edit suggestions (like Anders and many others
   did, thank you!). You can also get in touch via email
   (userhostileweb—at—neustadt.fr) or, if you're on Hacker News or Reddit,
   share your thoughts there.
   —

   Parimal Satyal is a Paris-based designer/geek who enjoys cosmology,
   dark beer, the open internet, metal music and foreign languages. More–

   Neustadt.fr is his collection of essays, reviews and music.
   ← Neustadt.fr

A Beginner's Guide to Crafting a Blog with Metalsmith

   30 septembre 2016 — Parimal Satyal

   Neustadt.fr is built with Metalsmith, a node.js-based static site
   generator. In this tutorial, I show you how you can build your own
   Metalsmith blog from scratch.

   Neustadt.fr started, as many things have, with a post on Hacker News. I
   stumbled upon Jendrik Poloczek's very simple, readable website after
   one of his articles made it to the front page. His website is
   apparently powered by Pelican, a Python-based static site generator. I
   didn't really know what that meant but I was intrigued.

   This came at a time when I was getting increasingly frustrated with the
   wastefulness, bloat and disregard for privacy in modern web design. Not
   to mention the layers and layers of dependencies. People who want a
   simple website today often end up with a dynamic database-dependent
   WordPress blog running a theme that has widgets, infinite scroll,
   lightbox, a media gallery, Google Analytics and jQuery animations
   built-in. And all they wanted was to post a few articles and photos
   every month. It's absurd.

Why go static?

   Simplicity and speed. Call it nostalgia but I like to keep things
   small, simple and manageable. There's something beautiful about a
   website in standard HTML, CSS and (minimal) Javascript that can be
   hosted pretty much anywhere. Even Neocities.

   With a static website, you don't have to worry about databases, SQL
   injections, security patches and server environments. Need to change
   hosts? Migrating is as simple as copy/paste. Then there's the speed.
   Between the caching and not having to query databases to dynamically
   generate pages every time, you end up with something very robust. A
   friend who recently went static had an article make it to the front
   page of Hacker News, bringing in about 3 GB of traffic in one day.
   Since he was only serving plain HTML and CSS, his server handled it
   just fine.

Why Metalsmith?

   Before choosing Metalsmith, I looked into Python-based Pelican,
   Ruby-based Jekyll and Middleman, node.js-powered Wintersmith and
   Golang-powered Hugo. They are all capable static site generators with
   active developer and user communities so you'd really be okay with any
   of them.

   What I loved about Metalsmith is that it does nothing out of the box.
   It just takes a source directory and spits everything out into a
   destination directory. If you want it to do anything meaningful, you
   need to build your own workflow with plugins. And in Metalsmith,
   everything is a plugin.

   Instead of having to disable features I don't need, I could simply add
   the ones I want from a growing ecosystem of over a 130 plugins.
   Markdown, drafts, permalinks, code highlighting, templates - they're
   all optional plugins.

Requirements and audience

   This tutorial is for beginners, so it'll be quite detailed and verbose.

   Our example blog will be extremely simple: an index page with a list of
   all articles, a page for each article and an about page. It'll be the
   personal website of fictional astrophycisist (and retro music
   enthusiast) Tara Himmels, who'll name her blog Electroniq.

   I assume only that you are familiar with basic HTML/CSS and are at
   least a little bit comfortable using the command line (or not scared of
   it, at the very least). You'll also need to be familiar with very basic
   Javascript syntax. If you're not, don't worry; I'm no programmer
   either, you can learn as you go.

   We'll be writing our posts in Markdown, a simple markup language that
   lets you format your posts easily without having to throw in HTML tags
   everywhere. It then converts it to HTML for you. If you don't know it,
   you can learn it in 5 minutes.

   You don't need to know node.js. I didn't when I started.

   To complete this tutorial, you will need:
     * A computer running Windows, Mac OS X or almost any UNIX-based OS
     * Shell access (like Terminal on Mac)
     * A text editor (like Brackets or vim)
     * A web browser
     * A web host if you want to go live (we'll talk about this later)

   I usually also use Git for version control. But let's keep things
   simple for this tutorial.

Installing Node.js and Metalsmith

   If you're running Windows or Mac OS X, the easiest way to install
   Node.js is to download and install the precompiled binaries (or via
   Homebrew on the Mac). If you're running Linux, you can use your
   distro's package manager.

   This installs both Node.js and npm, the node package manager that we'll
   be using to install all our plugins.

   Once you have npm installed, you can go ahead and install metalsmith.
   Before you do so, let's create a project directory. On the command
   line, type this (omitting the $, which is just a convention to denote
   the prompt):
$ mkdir electroniq

   Then cd into that directory and make a new folder called src.
$ cd electroniq
$ mkdir src

   We'll use this folder to store all our source files: our posts in
   Markdown (.md) and our site assets (.css, .js and image files). But
   first, we'll need a package file for all our dependencies (every plugin
   in Methalsmith is a dependency). We'll write this in a format called
   JSON.

   On your root folder (electroniq, which I'll refer to simply with the
   conventional forward slash /) , create a file called package.json with
   this text:
{
  "name": "electroniq",
  "version": "1.0.0",
  "private": true,
  "description": "Electroniq is astrophysicist (and retro music enthusiast) Tara
 Himmels' blog.",
  "author": "Tara Himmels"
}

   For now, we're just seting up your node.js environment with some meta
   information. But the package.js file does a lot more; it holds
   everything together. Every time we use a plugin, we'll need to declare
   it in this file. Luckily, this can be automated; let's install a plugin
   to see it in action.

   We'll start by installing metalsmith itself. On your root folder, type:
$ npm install metalsmith --save

   This installs metalsmith and creates a node_modules folder with all of
   metalsmith's dependencies. The --save flag automatically also adds
   metalsmith to your package.json file; if you open it now, it'll look
   something like this:
{
  "name": "electroniq",
  "version": "1.0.0",
  "private": true,
  "description": "Electroniq is astrophysicist (and retro music enthusiast) Tara
 Himmels' blog.",
  "author": "Tara Himmels",
  "dependencies": {
    "metalsmith": "^2.2.0"
  }
}

   We now have nodejs, npm and Metalsmith installed. We also have a
   project directory, a source directory, a package dependency file and a
   folder that'll hold all of our node modules.

   Now to start forging.

A basic workflow

   First things first, we need a build file to define our metalsmith
   workflow -- a succession of plugins. Create a file called build.js and
   type/paste this in:
var metalsmith = require('metalsmith');

metalsmith(__dirname)
  .metadata({
    site: {
      name: 'Electroniq',
      description: "Electroniq is astrophysicist (and retro music enthusiast) Ta
ra Himmels' blog."
    }
  })
  .source('./src')
  .destination('./public')
  .build(function (err) {
    if (err) {
      console.log(err);
    }
    else {
      console.log('Electroniq built!');
    }
  });

   A basic Metalsmith setup can be more compact than this, but we've added
   a few things that are important. Let's go over this line by line. If
   you know what's going on here, feel free to skip ahead.

   First, we require metalsmith itself:
var metalsmith        = require('metalsmith');

   We'll need to do this for every plugin we use. Most dependencies on
   your package.json file will also need to be declared/required here.

   Next, we call the main metalsmith() function itself and define metadata
   that'll be useful later. These values can be called from any of our
   templates. For now, we'll just include a name that we can later use as
   in <title> tag of our blog.

   Then, we define our source folder (./src), a destination folder where
   Metalsmith will output our static site (./public), and call the build()
   function to run our workflow.

   We've also included basic error catching. Should Metalsmith encounter
   an exception, it'll be appended to the Javascript console, which will
   be useful for debugging. Otherwise, it'll post a message to the
   Termnial indicating that the build was successful.

   Now, we'll create a bridge between package.json to our newly-forged
   build.js file. Open package.json and add the main and scripts bit at
   the end, like so:
{
  "name": "electroniq",
  "version": "1.0.0",
  "private": true,
  "description": "Electroniq is astrophysicist (and retro music enthusiast) Tara
 Himmels' blog.",
  "author": "Tara Himmels",
  "dependencies": {
    "metalsmith": "^2.2.0"
  },
    "main": "build.js",
  "scripts": {
    "prestart": "npm install",
    "start": "node ."
      }
}

   These lines we added tells node that build.js is the main entry point
   for our project. We then define two scripts; the start bit essentially
   just tells node to run this main script and the optional prestart bit
   just installs or updates all your dependences first.

   This is what your electroniq directory should now look like :
.
├── node_modules/
│   └── ...
├── src/
├── build.js
└── package.json

   You now have a basic Metalsmith setup. It doesn't do anything yet
   (other than copy the nothingness in your source directory to your
   destination directory), but we can technically build our website.

   Give it a go:
$ npm start

   It's nice to get that little "Electroniq built!" message on the
   console, isn't it? Now let's make Metalsmith actually do something.

Markdown and Frontmatter

   Using Markdown to write your posts makes sense: you can format text,
   the text remains readable and the whole thing converts easily to
   standard HTML. In fact, this tutorial is written in Markdown.

   To use Markdown, you need to install the plugin first :
$ npm install metalsmith-markdown --save

   Open build.js. First, before using the plugin, we must require it at
   the start of our file:
var metalsmith = require('metalsmith');
var markdown = require('metalsmith-markdown');
// ...

   Now add Markdown between .destination() and .build() like so:
// ...
    .source('./src')
    .destination('./public')
    .use(markdown())
    .build(function (err) {
// ...

   And that's it. This is how you add plugins to your workflow.

   Of course they usually take parameters, but we'll see that later. It's
   important to remember that the order of plugins is usually important;
   think of it as a pipeline. Each action passes on its results to the
   next.

   Now let's write a sample article in Markdown. We'll title it "Hello
   Universe".

   Create a new file in your src folder called hello-universe.md:
---
title: "Hello World"
date: 2016-10-12
blurb: An introduction to our blog Electroniq
---

## Welcome to Electroniq

*Electroniq* is a new blog about space, distant galaxies and black holes.

We'll talk about [the holographic principle](https://en.wikipedia.org/wiki/Holog
raphic_principle), dark matter and the beauty of space in infrared light.

This blog is run by **Tara** and **Elias**.

   The bit at the top between the --- is called fontmatter. Here, it's in
   YAML but that's not too important. These are just metadata that we'll
   be able to access in the template. Here we've included a title, a date
   and a blurb. You could also use add these kind of key/value pairs for
   keywords, categories, author name, modified date… you get the idea.

   We don't have a template to display this content yet, but since we
   added Markdown to our workflow, Metalsmith will still be able to
   convert it to HTML. Build your project to check:
$ npm start

   This will create a new folder called public with a file
   hello-universe.html. Your root directory should now look like this:
.
├── node_modules/
│   └── ...
├── src/
│   └── hello-universe.md
├── public/
│   └── hello-universe.html
├── build.js
├── Makefile
└── package.json

   Open the generated hello-universe.html file on your editor. It will
   simply contain:
<h1 id="welcome-to-electroniq">Welcome to Electroniq</h1>
<p><em>Electroniq</em> is a new blog about space, distant galaxies and black hol
es.</p>
<p>We&#39;ll talk about <a href="https://en.wikipedia.org/wiki/Holographic_princ
iple">the holographic principle</a>, dark matter and the beauty of space in infr
ared light.</p>
<p>This blog is run by <strong>Tara</strong> and <strong>Elias</strong>.</p>

   Metalsmith has converted your article from Markdown into HTML. This is
   a good start but our page is incomplete. There's no
   or navigation or any structure, and we're not using information in our
   YAML frontmatter.

   What we need is a template to display this page. Let's make one now.

Templates

   One of the reasons to use a static site generator is to be able to use
   templates with HTML markup and variables we can reuse on different
   pages without having to repeat any of it.

   Metalsmith comes with a plugin that lets you write your templates in
   pretty much any templating engine. If you don't know what these are,
   don't worry. They're a way we can access data and variables from within
   our templates. For this project, we'll use Handlebars.

   Let's start by installing the metalsmith templating plugin, called
   metalsmith-layouts:
$ npm install metalsmith-layouts --save

   We'll also install Handlebars while we're at it:
$ npm install handlebars --save

   We know that these dependencies will automatically be added to our
   package.json file. Now let's add them to our workflow. Open build.js
   and first require our two new packages:
var metalsmith = require('metalsmith');
var markdown = require('metalsmith-markdown');
var layouts = require('metalsmith-layouts');
var handlebars = require('handlebars');
// ...

   And then add them to our workflow:
// ...
    .source('./src')
    .destination('./public')
    .use(markdown())
    .use(layouts({
            engine: 'handlebars',
            directory: './layouts',
            default: 'article.html',
            pattern: ["*/*/*html","*/*html","*html"]
        }))
    .build(function (err) {
// ...

   This snippet tells Metalsmith to use Handlebars templates, look for
   them in the layouts directory and use a template called article.html by
   default. We also define a pattern for layout files; in this case,
   they're any files with the .html extension.

   Let's create our layouts directory and write our default template now:
$ mkdir layouts

   Inside this folder, create a file called article.html with these
   contents:
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>{{ title }} - {{ site.name }}</title>
    <meta name="description" content="{{ blurb }}" />
  </head>
  <body>
    <article>
      <h1>{{ title }}</h1>
      <div class="meta">
          {{#if date}}Published: {{ date }}{{/if}}
      </div>
      {{{ contents }}}
    </article>
  </body>
</html>

   It's a pretty standard HTML page, except for the Handlebars tags in {{
   }}. These are placeholders that will be replaced by actual content in
   the static output. For example, we want the name of our website in our
   page's <title>, along with the title of the article.

   Remember we already defined the site name in build.js as global
   metadata, like so:
// ...
metalsmith(__dirname)
  .metadata({
    site: {
      name: 'Electroniq',
    }
  })
// ...

   In the template, we can access this information via the {{ site.name }}
   variable. The other tags — title and and date — come from our article's
   frontmatter.

   The article itself can be accessed quite through the {{{ content }}}
   tag. We're using three curly brackets here instead of the usual two
   because we don't want Handlebars to escape any characters (Markdown
   does that for us).

   There's also an {{#if date}} conditional tag there, but we'll explain
   that a bit later.

   To see what Metalsmith generated for us with this template, build the
   project:
$ npm start

   And open public/hello-universe.html in your editor. You should see
   something like this:
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Hello World - Electroniq</title>
    <meta name="description" content="An introduction to our blog Electroniq" />
  </head>
  <body>
    <article>
      <h1>Hello World</h1>
      <div class="meta">
          Published: Wed Oct 12 2016 02:00:00 GMT+0200 (CEST)
      </div>
      <h2 id="welcome-to-electroniq">Welcome to Electroniq</h2>
<p><em>Electroniq</em> is a new blog about space, distant galaxies and black hol
es.</p>
<p>We&#39;ll talk about <a href="https://en.wikipedia.org/wiki/Holographic_princ
iple">the holographic principle</a>, dark matter and the beauty of space in infr
ared light.</p>
<p>This blog is run by <strong>Tara</strong> and <strong>Elias</strong>.</p>

    </article>
  </body>
</html>

   So we now have an article page.

   What we don't have is an index page that lists all the articles we
   publish. To do this, we'll need a plugin called metalsmith-collections.
   Go ahead and install that now.
$ npm install metalsmith-collections --save

   As always with a new plugin, require it and then add it do your
   workflow in build.js like so:
// ...
var collections = require('metalsmith-collections');
// ...
    .source('./src')
    .destination('./public')
    .use(collections({
      articles: {
        pattern: 'articles/**/*.md',
        sortBy: 'date',
        reverse: true
        },
      }))
    .use(markdown())
    .use(layouts({
// ...

   A collection is like a filter based on certain criteria. Here, we'll
   simply want a list of all our articles in reverse-chronological order
   (so newest first). The pattern: 'articles/**/*.md' bit is important; it
   tells the plugin that it should consider any Markdown files in the
   /src/articles directory part of the collection.

   But that folder doesn't exist yet; our one article lives in /src/.
   Let's fix that now. Create our articles folder under /src:
$ cd src
$ mkdir articles

   Now let's move our existing article there.
$ mv hello-universe.md articles

   While we're at it, let's add a second article. You should be able to do
   this on our own. Simple create a new file in the articles directory
   with any filename that ends in .md.

   So, for example, you could write about Spooky Action at a Distance and
   name the file spooky-action.md :
---
title: "Spooky Action"
date: 2016-10-14
blurb: "What would Einstein make of quantum entanglement today?"
---

## Spooky Action at a Distance

Some text here.

   Ok, we now have two articles. This is starting to look more like a
   blog.

   But we don't have a layout for the index page quite yet. Let's create
   that now. Switch to our layouts directory create a copy of our article
   page and name it index.html.
$ cd ../layouts
$ cp article.html index.html

   Change the code so it looks like this:
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>{{ site.name }}</title>
    <meta name="description" content="{{ site.description }}" />
  </head>
  <body>
    <h1>{{ site.name }}</h1>

    <ul class="recent">
    {{#each articles }}
      <li>
        <div class="title"><a href="{{ path }}">{{ title }}</a></div>
        <div class="date">{{ date }}</div>
      </li>
    {{/each}}
    </ul>

  </body>
</html>

   In the <head> section, we've removed the bit with {{ title }}, which
   only exists for articles and left just the {{ site.name }} bit and
   we've switched out the {{ blurb }} for {{ site.description }}.

   The bit in between the <body> tags introduces new Handlebars code:
{{#each articles }}
...
{{/each}}

   This is a loop of all articles (the collection we previously defined).
   So this page will just be a list of all articles we write, with a title
   and a date for each.

   However, before Metalsmith is able to generate our index page in our
   /public directory, we need a file called index.md file in the /src
   folder. Create this file now:
---
layout: index.html
---

Partials

   It's a good start but we're repeating code in our two template files.
   This is not ideal because if we ever want to change something in the
   header, we'd need to change it on every template that contains it. To
   avoid this, we can split reusable code into smaller sub-templates, or
   partials, that we can call from our main templates.

   Let's create two partials, one for the header and one for the footer.
   Metalsmith doesn't impose any rules on where you put these files and
   what you call them; we're free to structure it any way we want. We'll
   keep things logical and have them live in a folder called partials in
   our layouts folder.

   Create the folder now:
$ cd layouts
$ mkdir partials

   In this folder, create a file header.html that contains:
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>{{#if title }}{ {title }} - {{/if}}{{ site.name }}</title>
    <meta name="description" content="{{#if blurb}}{{ blurb }}{{else}}{{#if desc
ription}}{{ description }}{{else}}{{ site.description }}{{/if}}{{/if}}" />
  </head>
  <body>

   This is the bit that goes at the top of every file. You'll notice that
   we've again replaced the title from {{ site.name }} to a slightly more
   complicated-looking {{#if title }}{ {title }} - {{/if}}{{ site.name }}.
   The meta description has something similarly complex. Why?

   We're going to call the same header partial from our index page as well
   as our article page but there are small differences in our header
   between these templates. What we're doing here is using conditional
   tags to show different information depending on whether the page is an
   index page or an article page.

   The conditional if tag in handlebars looks like this:
{{#if title }}
  {{ title }}
{{/if}}

   All this says is that if the variable title exists, display it. But we
   know that title variable only exists for article pages (in the YAML
   frontmatter), not for index pages. So now our very smart header partial
   prepends the article title with a dash to the title if it's called from
   the article page.

   Same thing for meta description, except this is an if... else
   conditional block:
{{#if blurb}}
  {{ blurb }}
{{else}}
  {{ site.description }}
{{/if}}

   As you've by know figured, this uses the blurb variable if one exists
   in the frontmatter. Else, it'll just use the site description we
   defined in our build.js file. This again means that the meta
   description will be the blurb for an article page and the
   site.description and for the index page, which makes sense.

   Now create a file called 'footer.html' that contains simply:
</body>
</html>

   Nothing too surprising here.

   Now we have to let Metalsmith know that we've created these partials so
   we can invoke them from inside our templaces. To do this, open build.js
   and modify the parameters for our layouts plugin so they look like
   this:
.use(layouts({
      engine: 'handlebars',
      directory: './layouts',
      default: 'article.html',
      pattern: ["*/*/*html","*/*html","*html"]
      partials: {
        header: 'partials/header',
        footer: 'partials/footer'
        }
    }))

   Now that our partials are defined, it's time to use them.

   Edit both article.html and index.html and replace the header that's
   there:
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>{{ site.name }}</title>
    <meta name="description" content="{{ site.description }}" />
  </head>
  <body>

   with just this one line, which is Handlebars syntax for calling
   partials:
{{> header }}

   Do the same with the footer, replacing
</body>
</html>

   with:
{{> footer }}

   We're almost ready. The only thing missing now is a way to navigate
   from an article page back to the index page. Open layout/article.html
   and add the <header> block between {{> header }} and <article> so it
   looks like this:
...
{{> header }}
  <header>
    <a class="back-to-index" href="../index.html">&larr; Index</a>
  </header>
  <article>
    <h1>{{ title }}</h1>
...

   This just adds a ← Index link at the top of the page (a little like on
   this website).

   Now try building your blog again and moving between an article page and
   the index. (Moving the other way might not work yet, we'll fix this
   when we get to the permalinks bit.)

Adding an About Page

   Finally, let's add an About page. This is simple. Just create an
   about.md file in the /src directory. Here too, you can add any
   key/value pair in the YAML frontmatter. Or remove them, as we've done
   with date, which we won't need.
---
title: "About"
blurb: "Tara Himmels is an astrophysicist and retro music enthusiast. Electroniq
 is her blog."
---

Hello, my name is Tara Himmels.

If you'd like to get in touch with me, you can contact me [via email](tarahimmel
s@example.com).

In the meantime, I do hope you enjoy your day on this *pale blue dot* that is ou
r home.

   Let's edit to the footer so there's a link to this page; people
   wouldn't be able to get to it otherwise!

   If you open /layout/partials/footer.html in our text editor, it should
   look like this :
</body>
</html>

   Change it to this:
<nav>---<br /><a href="/about">About this blog</a></nav>
</body>
</html>

   You could build your blog now and view your page at /about.html. It'll
   have used our default 'article.html' template. But you notice that our
   in the footer doesn't actually work (yet).

   This is because our about page actually lives at /about.html and not
   /about, which is prettier. Let's fix that now.

Routes and Pretty Permalinks

   Right now, our index page lives at /index.html, the about page at
   '/about.html' and any blog post at /articles/title-of-the-article.html.
   Ideally, we wouldn't need the .html bit.

   This is the URL structure we want:
     * Home page: /
     * About page: /about
     * Article page: /title-of-the-article

   Notice that these are root-relative links, / being the root. The root
   could really be a number of other things: a top-level domain like
   https://electroniq.org/; a subdomain like
   https://electroniq.example.org/; heck, even a local address like
   localhost:8081/ (we'll see this again in the next section).

   To enable this kind of routing, we'll need the metalsmith-permalinks
   plugin.

   This will allow us to write custom URLs: with a date, maybe, or an id
   or an author name. As long as this information exists in the
   front-matter, you can use it in your URL. In our case, we'll only be
   using the title. This will give use the URL structure we want:

   Let's install this plugin:
$ npm install metalsmith-permalinks --save

   Then open build.js and require it:
var permalinks = require('metalsmith-permalinks');

   And finally, add it to our workflow, right before layouts:
// ...
    .use(markdown())
    .use(permalinks({
      relative: false,
      pattern: ':title',
    }))
    .use(layouts({
// ...

   And that's it. The pattern of our URLs is straightforward, we'll simply
   use the title of the post as provided in the frontmatter. So a title
   like "Spooky Action" will become /spooky-action.

   We've also set relative to false. If this were set to true, Metalsmith
   would make a copy of any resource on the source folder in all
   sub-folders. But in our case, this isn't necessary.

   Build your Metalsmith blog now to see your new URLs in action:
$ npm start

   This is what your root directory should look like now:
.
├── node_modules/
│   └── ...
├── layouts/
│   └── index.html
│   └── articles.html
│   └── reviews.html
│   └── partials/
│      └── footer.html
│      └── header.html
├── src/
│   └── articles/
│      └── hello-universe.md
│      └── spooky action.md
│   └── about.md
├── public/
│   └── about-tara-himmels/
│      └── index.html
│   └── hello-world/
│      └── index.html
│   └── spooky-action/
│      └── index.html
├── build.js
└── package.json

   As you can see, the /public folder now represents every page as a
   folder with its own index.html file.

Watching, (local) serving and drafts

   You'd probably want to preview your articles before you publish them.
   You could, of course, open the generated index.html in your browser and
   reload your page everytime you change something, or you could have live
   preview.

   To do this, Metalsmith would need to watch your folder and rebuild any
   files in which it detects changes and serve these pages with its own
   little webserver. Thankfully, Metalsmih comes with a pair of plugins
   that do just this: metalsmith-watch and metalsmith-serve.

   Start by installing them:
$ npm install metalsmith-watch --save
$ npm install metalsmith-serve --save

   Setting them up is super easy. Open your build.js file and first
   require these plugins:
var serve = require('metalsmith-serve');
var watch = require('metalsmith-watch');

   Then just add them to your workflow around the end, right before the
   build() function:
// ...
.use(serve({
  port: 8081,
  verbose: true
}))
.use(watch({
    paths: {
      "${source}/**/*": true,
      "layout/**/*": "**/*",
    }
  }))
.build(function (err) {
// ...

   The serve command essentially tells Metalsmith to serve the pages using
   a local server running on port 8081. The 'verbose' option will output
   status updates to the command line (everytime it detects a change to a
   file, for example; this is helpful for when you've set a wrong path and
   the server responds with a 404).

   The watch commands takes paths as parameters; these are essentially
   folders it should watch for changes. We're going to include the source
   folder (obviously) and our layout folder.

   Build your Metalsmith blog now to test our local server:
$ npm start

   Now go to address http://localhost:8081 on your local browser and you
   should see your index page.

   I should mention that while the serve/watch combo works really well
   when you're editing single articles, in my experience you shouldn't
   rely on it for changes to your template file. If you notice anomalies,
   just rebuild your blog.

   To do that, you'll need to first kill your server by hitting Ctrl + C
   (on Unix, Mac or Windows). This interrupts the current process. After
   that, it's the usual:
$ npm start

   Your very simple Metalsmith blog is now ready!

Going Live (aka. Deploying)

   This is where things get really fun.

   With a static website, going live is as simple as copying your /public
   folder to your remote public_html (or equivalent) folder. So your
   deployment process involves invoking npm start and uploading your
   public folder to your remote server. This could be any server: on
   Neocities, GitHub Pages or any old shared hosting account. You don't
   need PHP, Ruby, node, CGI, MySQl or anything fancy; just any old web
   server will do.

   For Neustadt.fr, I run an Nginx server on a Digital Ocean droplet and
   deploy using this one-line shell script I've named deploy.sh:
#!/bin/sh
rsync -av -e ssh public/* parimalsatyal@139.59.134.246:/var/www/neustadt.fr

   All it does is use the rsync command to sync the local /public folder
   with the public folder on my remote s (/var/www/neustadt.fr), via SSH.

   This way, I can update and make as many changes as I please locally and
   when I'm ready, deploy with just two commands:
$ npm start;
$ ./deploy.sh

Final Thoughts

   You can browse the completed example project (exactly as we left it
   here) on GitHub.

   This of course is only a start. We've built an exceedingly basic
   website that doesn't even have CSS styling. We've only scratched the
   surface of what is possible. But if you've come this far, you already
   know how to set up a Metalsmith project, edit your templates and add
   new pages.

   If you'd like to go further, I'd recommend checking out the Awesome
   Metalsmith list, which also has links to other tutorials. If you have
   questions, the Metalsmith Slack channel is a good place to them (I find
   that woody is often there is very helpful).

   This website itself is also built with Metalsmith. If you'd like, you
   can poke around my Metalsmith setup on GitHub.

   I hope this tutorial has been of help to you. If you spot errors or
   would like to suggest an edit, please get in touch via email
   (parimal-at-neustadt-dot-fr). Or feel free to submit a pull request to
   this article on GitHub . Thanks go out to Metalsmith and the active
   user/developer community for building and maintaining this beautiful
   static website generator.

   —

   Parimal Satyal is a Paris-based designer/geek who enjoys cosmology,
   dark beer, the open internet, metal music and foreign languages. More–

   Neustadt.fr is his collection of essays, reviews and music.
   ← Neustadt.fr

Teaching Myself German

   07 mars 2016 — Parimal Satyal

   I had been somewhat obsessed with Germany for the past year or so but
   there, on a small street off Könnerlitzstraße in the backdrop of loud,
   bright fireworks and sekt-induced mirth, something was absolutely
   clear: I had to learn German.

   This is a guide to teaching yourself German.

   Kinda. It's really an annotated list of links to resources I’m
   personally using to learn German. Maybe you'll find it useful too.

   This is the first time I'm learning a language on my own. But it isn't
   my first foreign language and I find that over time, you learn how to
   learn languages. I figure that if I'm motivated (check), curious
   (check) and willing to make mistakes (double check), I should be fine.
   That and if I'm somewhat disciplined about the whole thing.

   It's been working well so far and I'm now able to hold basic
   conversation (especially if it's about beer). My personal rules are
   simple:
    1. Practice everyday, even if it’s just 15 or 30 minutes. Even 5 will
       do if I'm super busy.
    2. Don’t stress out about things I don’t yet understand. It's exciting
       to think that one day I'll understand all that without even
       realizing how hard it once was, and I'll forget what it was like to
       hear the language as a string of odd sounds.
    3. Speak. Even if I make mistakes, even if I can’t find the right
       word, even if it would all be easier to say in English.

   I’d have added "4. Have fun with it", but that goes for most things in
   life. It’s a prerequisite for learning.

Back story

   (You can skip the back story and go directly to the resources if you’d
   like).

   The German verb for ’to celebrate’ is feiern. I associate this with the
   word for ‘fire', feuer. You might think this is because the two sound
   rather alike but that’s not really why. It has to do with ‘Silvester’,
   German for New Year’s Eve.

   On December 31, 2015 I learnt that the Germans really, really like
   their fireworks. It was exactly the sort of brazen disregard for safety
   for which my preconceived notions could not have prepared me. I was
   celebrating with close friends in Leipzig, 2 hours south of Berlin.
   Anders, a calm Swede who had experienced the madness in Berlin
   first-hand the year before had previously warned me:

     „You know those things that you normally shoot up in the air?
     Rockets? Yeah well people were launching them everywhere, even
     inside the metro. It was like a war zone!”

   Luckily, Leipzig doesn’t have a metro. It was still absolutely insane.
   I had been somewhat obsessed with Germany for the past year or so but
   there, on a small street off Könnerlitzstraße in the backdrop of loud,
   bright fireworks and sekt-induced mirth, something was absolutely
   clear: I had to learn German.

   I'd toyed with the idea of learning Deutsch for a while. I even
   considered learning it over French many, many years ago; I only picked
   the latter because my local Alliance Française had a nice café/bistro
   and the Goethe Institut didn’t. (Incidentally, this is also why I now
   live and work in Paris).

   My closest friend in Paris was German (he still is; he’s just not in
   Paris anymore) and he introduced me to German, mostly Bavarian, beer. I
   loved how the words looked and sounded: Hefeweiße, Dunkles Doppelbock,
   Reinheitsgebot, Märzenbier, Rauchbier. Then when he and Charlotte (who
   you’ll recall from my last essay) moved to Germany, I had two very good
   reasons to visit Deutschland. Since, I’ve been several times to five
   different cities and absolutely loved it every time.
   A fine selection of German beers: Ayinger Albairisch Dunkel, Ayinger's
   starkbier Celebrator and Ur-Krostitzer Pilsner A fine selection of
   German beers: Ayinger Albairisch Dunkel, Ayinger's starkbier Celebrator
   and Ur-Krostitzer Pilsner

   The turning point though was really Silvester in Leipzig. Everything
   else just fell into place after that.

   I’m into my fourth month now and I am quite happy with my progress. I
   was in Leipzig again just last month and was able to hold short
   conversations almost entirely in German. I naturally struggled to find
   the right words every now and then and could use only very simple
   structures but still, it was all quite encouraging.

   I owe this progress to the mind-blowing choice of (mostly) free
   resources to learn German on the internet. And the fact that I seem to
   have somehow surrounded myself with really nice people who speak German
   and don’t mind helping me out, but more about that later.

   First, resources to learn German:

Laying the Foundation: German Grammar

   I remember Charlotte learning German two years ago when she was still
   in Paris; now, she speaks it fluently. I asked her if she had any
   advice.

     "You need to really study the grammar," she said. "Otherwise things
     won’t make a lot of sense."

   She was of course right. Up until that point, I had been picking up
   words and phrases by ear but the structure of the language remained
   elusive. I knew that German had three genders — der (masculine), die
   (feminine) and das (neutral) — but I had no idea why "die Straße" (the
   street) would sometimes seemingly turn masculine and become, for
   example, "auf der Straße". Or why you'd sometimes say "das rote Auto"
   but other times "mit dem roten Auto". What I needed was a simple,
   comprehensive Grammar book.

   I found this in Basic German: A Grammar and Workbook by H. Schenke and
   K. Seago (available for free on archive.org). Especially if you’ve
   already some experience learning languages, you’ll find its direct
   approach rather efficient. It explains the basics of every major
   grammatical feature of German with examples and exercises, without
   going into too much detail. This is important; you don't want to get
   overwhelmed when you start.

   My advice is to go through each chapter even though you might not
   necessarily understand everything. Your mind will better internalise
   the grammar and make logical connections between words in sentences you
   might come across elsewhere. Words that you see everywhere like nach,
   zu and woher suddenly make (some) sense. My understanding of both
   written and spoken German improved dramatically after going through all
   the chapters.

   I’m re-reading this book now and find that the things I struggled with
   a little the first time now are quite logical.

   Note: Once you're done with this, you can move on to the Intermediate
   version of the same book, also available on Amazon.

Learn German from the Streets

   Learning basic grammar is essential but it won’t help you get a feel
   feel for language or understand the people who speak them.

   I learn best when I hear things in context: a conversation between
   friends or colleagues or even a passing remark overheard on the street.
   They might be "raw", unfiltered and not immediately accessible to the
   beginner but they give an insight into the language: the flow, the
   rhythm, the attitude.

   Easy German offers exactly that. It’s a series of short video
   interviews with people on the street, around a number of different
   subjects. My favourite ones so far are: „What do the Swiss think about
   Germany?”, „At the organic food market in Münster” and „In the pub”.
   They’re great for at least five reasons:
    1. You get to hear German as it’s really spoken, in its many many
       varieties and dialects.
    2. Most videos are subtitled in both English and German. You get
       follow along even when they deal with more complex topics, and pick
       up words and expressions as you go without getting frustrated.
    3. The hosts are fantastic! Cari, Manuel and the rest of the crew do
       an excellent job.
    4. The topics are interesting and quite contemporary: the refugee
       crisis, organic food, Christmas celebrations, flirting, bar/pub
       culture. 
    5. It’s free! (Vielen dank if you guys ever read this!). But you can
       support Easy German on Patreon.

   Easy German videos complement the grammar book quite nicely. I find
   myself going back to my favourite videos every now and then and
   understanding a little more each time. It’s very rewarding.

Start reading stories

   About three years ago, I remember discussing the Snowden revelations
   with Andy over many lunches in Boulogne-Billancourt. I was getting most
   of my information from The Guardian and he from Der Spiegel. I was
   quite surprised at how uninterested the French press seemed to be in
   the subject. Der Spiegel, on the other hand, seemed to continue
   publishing really interesting articles about surveillance, PRISM, about
   European complacency and data security.

   I told Andy that I'd love to be able to read Der Spiegel in German one
   day. But that's not the best place to start. I needed something
   simpler.

   Café in Berlin (available at Learn Out Live or Amazon) is a collection
   of short stories written entirely in German. Despite what the cover
   might suggest, it's set in present-day Berlin (with hipsters and
   kebabs), as experienced by a young Sicilian student who's looking for
   work. The author André Klein uses high-frequency word groups and
   informal slang so you can start learning street German that you can
   actually use in real life. The best part is that at the end of every 3-
   to 4-page chapter is a mini-dictionary of new words and expressions. I
   recommend reading the story completely in German first and trying to
   infer the meaning of words you haven't seen before. Then, you can go
   through the mini-dictionary and read it a second time.

   After this book, you can follow Dino on his adventures in other cities
   in Germany.

Watch YouTube videos

   I'm not sure there's a language teacher more enthusiastic than Ania. On
   her YouTube channel Learn German with Ania, Ania posts short videos
   about practical things, grammar and culture. Her explanations about
   grammar rules are especially good: the dative case, prepositions that
   take the accusative case, German sentence structure.

   The videos are short and are a great way to go review a particular
   grammatical structure quickly. Or to watch with breakfast before you
   head out to work/school/whatever.

Extr@ Deutsch (on YouTube)

   Lots of people learn (or learned) English watching episodes of Friends.
   Extr@ Deutsch is something like Friends for learning German in the same
   way that Starbucks is like a coffeeshop. You follow the lives of
   twenty-somethings (including an American exchange student, Sam) as they
   go about finding new ones to put themselves in ridiculous situations.

   It's cheesy as hell but hey, you'll almost certainly pick up words and
   expressions. You can watch Extr@ Deutsch for free on YouTube.

Living and working with Germanophones

   Finally, the best way to learn a language is obviously to live and work
   with people who speak the language. This is really the best part.
   Learning to speak a language also means learning the culture: new
   jokes, new perspectives and especially, new ways to embarass yourself.
   And I'm very lucky to be surrounded by German speakers even here in
   Paris.

   Case in point: I was having a deutschsprechendes lunch with Christine,
   a colleague from Luxembourg. It was at a Chinese restaurant and at the
   end of the meal, we were complaining about the lack of good dessert
   options. Then I remembered I'd bought some Kinder chocolates earlier
   and figured that that could be dessert when we got back to the agency.
   Excitedly, I said, "Ah, keine Sorge... ich kann dir Kinder geben!"

   Which roughly translates to, "Oh don't worry, I can give you children!"

   So, right. Or that time I was with my flatmates in Bordeaux and I said,
   "Hmm, ich hab' mein Schaf verloren...". I didn't understand why Joëlle
   burst out in laughter until she explained that "Schaf" is, in fact,
   sheep and not scarf, which would be "Schal". Didn't help that that same
   day I also said, "Ja, das kann ich dir ziegen". If I go to Germany now,
   they might just take me for a farmer.

   The point is, it's good to surround yourself with people who speak the
   language who can help you and correct you go. My flatmates both speak
   German and are learning French. It's the perfect environment for
   language sharing and linguistic schizophrenia. If you ever find
   yourself at our kitchen, you'll have to dodge a flurry of words in
   French, German, English and Swiss-German being thrown around
   carelessly. Yes, even Swiss-German. Turns out, to Christine's great
   horror, that I've started picking up Swiss words, expressions and even
   the accent.

   We'll see how the Germans take a guy from Nepal speaking German with
   just a touch of Schweizerdeutsch. Uf Widerluege!
   —

   Parimal Satyal is a Paris-based designer/geek who enjoys cosmology,
   dark beer, the open internet, metal music and foreign languages. More–

   Neustadt.fr is his collection of essays, reviews and music.
   ← Neustadt.fr

32c3 - Chaos Communication Congress

   06 janvier 2016 — Parimal Satyal

   Impressions and highlights from the 32nd Chaos Communication Congress,
   the biggest non-commercial, community-run hacker conference in the
   world.

   When my friend Charlotte's mom asked her why I was flying to Hamburg
   after Christmas, she explained that I was going to a sort of "geek
   conference about hacking". While this might not be the most accurate
   description of the annual Chaos Communication Congress, I think it
   conveys the spirit of the community just fine.

   This was my first time at 3C. Anders, whom I first met in Stockholm via
   Couchsurfing in 2010, has been going every year for the past eight
   years with a steadily-growing group of [DEL: friends :DEL]
   pilgrim-goers. Now having experienced it myself, I can only understand
   why.
   Congress Center Hamburg becomes Chaos Communication Congress for 32c3
   Congress Centrum Hamburg (CCH) turned into Chaos Communication Congress
   (CCC), December 27–30, 2015

32c3

   This 32nd edition brought about 12,000 nerds, hackers, free software
   advocates, crypto-people, hardware programmers, activists and artists
   together in a huge, insanely well-organized four-day congress the likes
   of which I've never seen before. Even more than the many
   thought-provoking talks and discussions, I was impressed by the fact
   that the entire thing is volunteer-run and community-supported.
   Everything. No employees, no corporate sponsorships. In fact, as far as
   I know, it's the biggest event of the sort anywhere in the world.

   It’s also a very welcoming community and veterans (like Anders) make it
   very easy for newcomers (like myself) to feel at home and join in on
   the fun.

"Geek conference"

   3C is indeed a "geek conference" in that, basically, it's a community
   of nerds and geeks sharing their passion for X with other engaged nerds
   and geeks. X could be anything: a multi-platform GUI for pass, the unix
   CLI password manager; a study of the Stasi photo archives; a discussion
   on EU policies on net neutrality; Tor and hidden services; Red Star,
   North Korea’s state-developed OS; Let's Encrypt, an open, free
   certification authority; the widespread (and misguided) attack on
   encryption by world governments; the (worryingly) increasing
   restrictions on freedom in France; the slow death of the open web;
   quantum physics and relativity. It's a lot to take in.

   Apart from the official talks and the 5-minute lightning talks that any
   member of the community can sign up to deliver, there are lots of other
   events and activities within 3C. The entire place is also a hackerspace
   for people working on 3D printing, Raspberry Pi and arduino projets,
   analog pixel-screens, dinner-making robots, lock-picking. All of this,
   of course, complemented by a liberal supply of Club Mate and
   Flora-Power bottles that, once empty, you can drop at one of the many,
   many recycling containers placed all over the Congress centre (once
   again, by volunteers).

Highlights

   The 3C Media team uploads every talk, with subtitles in German or
   English, to its server. (If you guys ever read this: thank you!) I
   couldn’t go to all the talks I wanted — there were far too many — but
   these are my personal highlights from the ones I did attend:

Internet Landscapes (Evan Roth)

   I loved that in Evan Roth’s work, he manages to convey that sense of
   fascination and wonder that we all felt when we first discovered the
   Internet.
   Watch the video here:
   https://media.ccc.de/v/32c3-7538-internet_landscapes

What does Big Brother see, while he is watching? (Simon Menner)

   From the official description:

     ... Over the course of three years, I was able to research the
     archives left by East Germany's Stasi to look for visual memories of
     this notorious surveillance system and more recently I was invited
     to spend some weeks looking at the archive by the Czechoslovak StB.
     Illustrating with images I have found during my research, I would
     like to address the question why this material is still relevant –
     even 25 years after the fall of the Iron Curtain.

   Watch the video here:
   https://media.ccc.de/v/32c3-7209-what_does_big_brother_see_while_he_is_
   watching

   Simon Menner’s book “Top Secret” is available for purchase on Amazon
   (US), Hatje Cantz (DE) and AbeBooks (FR). Sample images also on his
   website.

One year of securitarian drift in France (taziden, Adrienne Charmet)

   Taziden of la Fédération FDN and Adrienne of La Quadrature du Net
   explain the worrying reaction of the French government in restricting
   civil liberties in the wake of the Charlie Hebdo and November 13
   attacks in Paris.
   Watch the video here:
   https://media.ccc.de/v/32c3-7423-one_year_of_securitarian_drift_in_fran
   ce

Safe Harbor (Max Schrems)

   A presentation of the European Court of Justice’s ruling to invalidate
   Safe Harbour agreements in light of NSA mass surveillance, by the the
   Austrian "guy who sued Facebook and won". It’s a bit more complicated
   than that but Max Schrems has a terrifically entertaining way of
   explaining everything very clearly.
   Watch the video here: https://media.ccc.de/v/32c3-7513-safe_harbor

Ten years after ‘We Lost the War’ (rop, frank)

   A thought-provoking and sobering lecture by Rop Gonggrijp and Frank
   Rieger on the state of our world at the turn of 2015. From the official
   description:

     The talk „We Lost The War“ was presented at Congress ten years ago,
     causing quite a stir. It was a prediction of a dark future that did
     not sit well with many people, but unfortunately many predictions
     have come true meanwhile. This talk will try to address what comes
     next, as well as what the hacker community can do to make things
     better.

   Watch the video here:
   https://media.ccc.de/v/22C3-920-en-we_lost_the_war

Other Talks

   Those were just five of over a 150 talks on a wide variety subjects,
   including:
     * The state of internet censorship
     * Social innovation in favelas
     * Overcoming common UX/usability obstacles
     * The exhaust emissions scandal ("Dieselgate")
     * Amiga hardware design and programming
     * The evolution of brain-computer interfaces
     * Vector retrogaming
     * Tor onion services
     * Discrimination and ethics in a data-driven society
     * Quantenphysik und Kosmologie (in German)

   You can watch all talks, including the lightning talks, on the 32c3
   media website.

Intellect and Romance over Brute Force and Cynicism

   Craig Ferguson once described Doctor Who as "the triumph of intellect
   and romance over brute force and cynicism". I don't watch Doctor Who
   (yet), but I think this would be a fitting description of the
   aspirations of the Chaos Communication Congress community. Intellect
   and romance (or here, passion for learning and sharing) over brute
   force (oppression and aggression) and cynicism.

   Information over ignorance, critical thinking over rhetoric, play over
   consumption.

   See you next year for 33c3!

   Shout out to Anders, V, Alex, Anne and André — it was lots of fun
   hanging out with you crazy cats! And always remember, a man in the
   middle attack can come from anywhere ;)
   —

   Parimal Satyal is a Paris-based designer/geek who enjoys cosmology,
   dark beer, the open internet, metal music and foreign languages. More–

   Neustadt.fr is his collection of essays, reviews and music.
